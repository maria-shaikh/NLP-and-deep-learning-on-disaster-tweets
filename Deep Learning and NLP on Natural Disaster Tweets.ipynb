{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BUDT 737 Big Data and AI for Business\n",
        "\n",
        "## Team Project: Natural Language Processing with Disaster Tweets\n",
        "### Group 19:\n",
        "#### Aishwarya Sadagopan\n",
        "#### Madathil Geetanjali Menon\n",
        "#### Maria Shaikh\n",
        "#### Mingchen Feng\n",
        "#### Srikar Alluri\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a5xWAlE_N8_E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxgiHxNoY6Ob"
      },
      "outputs": [],
      "source": [
        "#importing necessary libraries\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HWDVNunmkri"
      },
      "outputs": [],
      "source": [
        "#storing csv files as dataframes\n",
        "df_train = pd.read_csv('train.csv', dtype={'id': np.int16, 'target': np.int8})\n",
        "df_test = pd.read_csv('test.csv', dtype={'id': np.int16})\n",
        "submission = pd.read_csv(\"sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "weyO3lgFOg56"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYf6ApI-E0A5",
        "outputId": "74404926-4cc9-411e-ccdd-150313678709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: (7613, 5)\n",
            "Test dataset shape: (3263, 4)\n"
          ]
        }
      ],
      "source": [
        "#Checking the dimensions of the dataset\n",
        "print(\"Train dataset shape:\", df_train.shape)\n",
        "print(\"Test dataset shape:\", df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8Ez_QnwFPp6",
        "outputId": "8591654a-3c0a-4092-d321-d9344a7b9989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of train dataset:\n",
            "   id keyword location                                               text  \\\n",
            "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
            "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
            "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
            "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
            "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
            "\n",
            "   target  flesch_kincaid  \n",
            "0       1             4.8  \n",
            "1       1             2.5  \n",
            "2       1             8.8  \n",
            "3       1            14.7  \n",
            "4       1             6.0  \n",
            "First few rows of test dataset:\n",
            "   id keyword location                                               text  \\\n",
            "0   0     NaN      NaN                 Just happened a terrible car crash   \n",
            "1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
            "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
            "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
            "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
            "\n",
            "   flesch_kincaid  \n",
            "0             4.5  \n",
            "1             6.8  \n",
            "2             6.0  \n",
            "3             9.6  \n",
            "4             5.2  \n"
          ]
        }
      ],
      "source": [
        "#checking out the first few rows of the datasets\n",
        "print(\"First few rows of train dataset:\")\n",
        "print(df_train.head())\n",
        "\n",
        "print(\"First few rows of test dataset:\")\n",
        "print(df_test.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "-PxdqfQKFnLU",
        "outputId": "a1e5c723-1337-4771-f054-fd39287017be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"b4fd3e9a-e3a1-40a3-807e-dbcf5b9d7671\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b4fd3e9a-e3a1-40a3-807e-dbcf5b9d7671\")) {                    Plotly.newPlot(                        \"b4fd3e9a-e3a1-40a3-807e-dbcf5b9d7671\",                        [{\"marker\":{\"color\":[\"Green\",\"Yellow\"]},\"x\":[\"0\",\"1\"],\"y\":[4342,3271],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"annotations\":[{\"font\":{\"color\":\"black\",\"size\":14},\"showarrow\":false,\"text\":\"4342\",\"x\":0,\"xanchor\":\"center\",\"y\":4342,\"yanchor\":\"bottom\"},{\"font\":{\"color\":\"black\",\"size\":14},\"showarrow\":false,\"text\":\"3271\",\"x\":1,\"xanchor\":\"center\",\"y\":3271,\"yanchor\":\"bottom\"}],\"title\":{\"text\":\"Distribution of target variable in training dataset\"},\"xaxis\":{\"title\":{\"text\":\"Target Variable\"}},\"yaxis\":{\"title\":{\"text\":\"Count\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b4fd3e9a-e3a1-40a3-807e-dbcf5b9d7671');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "\n",
        "#counting the number of examples with target=0 and target=1 through an interactive plot\n",
        "counts = df_train['target'].value_counts()\n",
        "\n",
        "fig = go.Figure(data=[go.Bar(x=[\"0\", \"1\"], y=counts.values, marker_color=['Green', 'Yellow'])])\n",
        "\n",
        "for i, count in enumerate(counts.values):\n",
        "    fig.add_annotation(x=i, y=count, text=str(count), showarrow=False, font=dict(color='black', size=14),\n",
        "                       xanchor='center', yanchor='bottom')\n",
        "\n",
        "fig.update_layout(title='Distribution of target variable in training dataset',\n",
        "                  xaxis_title='Target Variable',\n",
        "                  yaxis_title='Count')\n",
        "\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "aQ3N3CMUFxSh",
        "outputId": "2664e0ce-92ed-44e6-881e-4324f81a34ab"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"bc34aa4d-0033-4044-b9f9-fee394c3f6b3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bc34aa4d-0033-4044-b9f9-fee394c3f6b3\")) {                    Plotly.newPlot(                        \"bc34aa4d-0033-4044-b9f9-fee394c3f6b3\",                        [{\"name\":\"Train\",\"nbinsx\":50,\"opacity\":0.5,\"x\":[69,38,133,65,88,110,95,59,79,52,43,129,76,39,56,14,13,16,17,28,22,17,11,21,8,30,21,18,9,18,8,55,67,82,34,76,122,55,140,22,114,61,120,44,92,96,97,63,114,138,73,75,134,95,130,135,97,124,119,138,85,135,98,138,80,76,85,140,98,123,129,139,139,35,90,90,67,67,95,91,142,98,80,132,79,136,67,142,128,47,46,57,93,79,49,138,138,136,53,97,124,139,49,110,138,73,138,53,125,69,83,60,109,34,138,138,138,54,138,138,139,123,136,72,130,128,132,110,135,61,27,34,114,101,78,136,136,136,80,136,104,110,75,84,135,97,140,136,95,71,126,136,126,87,83,70,138,80,136,136,129,136,75,112,136,26,68,104,87,62,136,116,110,138,106,85,136,87,103,89,124,72,107,110,34,83,103,73,121,109,110,87,103,103,133,66,96,110,47,102,97,110,110,98,98,64,120,110,69,101,110,43,110,127,43,105,82,90,136,24,136,94,89,125,106,131,123,135,86,42,128,78,140,122,134,73,139,133,136,111,136,138,46,120,115,62,138,41,123,85,139,139,118,138,138,84,91,148,92,139,124,148,144,140,87,139,139,95,87,123,139,138,46,96,49,126,17,139,99,120,36,115,65,25,142,49,139,133,142,73,137,88,97,82,106,134,140,114,70,113,28,137,138,133,91,94,120,35,65,65,116,78,133,78,132,110,125,98,133,96,103,34,120,27,140,99,135,131,107,107,139,91,134,81,44,126,41,136,141,63,102,136,136,138,122,83,89,103,98,89,89,103,102,127,141,107,96,73,103,139,103,104,140,103,89,103,84,97,138,137,89,88,89,88,139,118,137,137,103,97,117,135,123,31,100,136,105,105,18,107,58,85,73,79,81,136,48,139,115,135,101,23,136,105,127,107,105,81,100,110,105,85,47,80,64,97,67,85,59,21,98,27,64,136,141,139,46,118,39,61,136,24,98,21,80,56,79,89,107,46,60,35,48,136,120,91,107,100,101,48,63,123,113,90,80,94,115,80,127,102,109,108,88,95,69,137,115,138,112,45,106,144,141,112,101,127,133,77,79,56,117,17,40,136,127,28,47,122,133,87,122,122,122,124,62,122,67,42,130,122,122,136,103,89,122,122,122,133,122,80,122,122,122,131,122,53,122,112,92,34,125,102,60,131,126,117,131,99,114,96,131,117,121,75,116,108,138,106,128,73,49,79,81,114,70,139,52,126,126,97,120,133,96,138,84,136,107,138,49,75,44,88,88,105,79,30,137,54,44,126,106,138,123,104,83,138,112,94,104,115,137,136,95,139,112,129,137,106,126,135,129,106,98,140,107,107,138,83,91,140,138,112,83,98,99,84,98,140,112,140,26,133,126,141,151,117,96,132,136,124,137,134,138,140,26,56,136,136,143,140,26,129,138,150,26,150,139,129,61,130,23,44,92,131,38,22,120,75,137,66,47,40,80,101,88,19,92,125,140,39,77,125,75,38,61,118,118,59,93,115,100,93,76,125,110,29,33,140,76,91,98,135,139,139,68,120,86,141,41,70,105,79,127,95,43,129,121,123,56,18,95,37,139,96,104,32,96,139,136,139,79,85,81,64,62,127,59,97,132,68,86,78,96,44,39,58,121,45,52,57,43,67,90,46,139,48,76,59,55,68,115,110,35,32,76,55,80,46,50,72,51,99,91,136,134,112,138,118,52,54,73,125,26,35,116,143,59,117,22,91,37,31,75,87,140,78,54,26,26,126,86,136,139,19,12,140,87,84,89,69,115,95,139,49,138,114,119,59,41,62,68,117,106,51,139,130,130,126,135,138,64,34,125,49,111,38,137,139,71,134,28,97,117,20,61,48,51,65,72,140,100,55,41,65,33,73,89,34,68,34,32,41,40,88,66,74,68,132,24,14,62,86,122,134,108,92,31,97,73,120,121,74,54,116,65,94,114,37,32,53,24,99,58,74,23,48,97,118,26,88,119,35,77,128,70,46,33,121,90,68,88,79,144,49,137,40,97,95,121,140,15,37,144,123,93,118,55,138,53,58,134,42,67,105,80,129,122,112,85,127,121,139,46,20,32,122,135,65,46,109,129,134,138,129,110,97,142,121,137,134,101,82,120,113,131,138,35,66,30,137,92,136,139,139,138,114,137,133,133,108,115,137,139,97,139,136,139,139,116,129,97,139,133,139,129,55,139,130,139,139,133,129,48,139,123,101,68,33,96,122,138,25,86,85,51,48,132,86,82,104,71,84,113,77,85,110,138,132,139,123,56,101,139,60,125,41,45,72,104,132,83,121,99,38,81,100,119,34,116,136,99,132,126,121,36,83,139,114,18,114,144,120,125,39,66,122,138,66,56,35,132,138,132,124,35,138,108,144,125,125,138,114,70,78,136,35,37,78,64,87,87,45,107,82,49,87,58,135,35,45,94,134,57,47,43,136,35,88,65,97,136,137,44,138,37,132,128,82,55,136,66,135,136,109,138,40,130,121,138,43,69,119,96,77,140,135,105,126,67,116,127,74,113,86,140,73,93,74,139,31,31,98,99,92,142,136,140,139,100,120,135,57,92,75,79,79,79,79,144,99,106,79,92,138,82,63,142,54,140,92,105,131,106,136,138,79,135,117,92,120,83,123,135,83,136,97,110,125,136,83,83,114,105,139,83,83,138,114,96,131,140,83,138,105,126,87,83,84,117,130,47,82,119,131,93,137,69,102,133,78,129,36,86,121,82,144,103,120,110,69,88,125,56,76,97,117,64,137,136,141,122,131,122,96,79,91,74,137,94,136,97,121,62,101,113,141,135,140,137,133,139,62,127,113,127,140,66,94,137,119,136,136,125,124,109,79,136,138,19,39,157,132,132,136,140,70,113,80,41,71,75,63,44,139,85,83,52,111,95,134,112,61,101,103,52,139,50,87,106,140,82,114,135,114,115,59,64,72,138,139,44,89,57,124,136,18,93,86,75,47,115,76,40,74,136,112,94,133,102,140,136,84,93,140,110,119,140,95,118,127,142,140,131,130,66,56,126,132,111,125,129,99,115,108,139,113,82,137,96,91,121,115,116,138,135,82,139,65,129,138,130,91,82,140,130,85,128,126,112,50,49,138,68,112,140,127,127,139,105,123,130,33,108,131,135,83,100,94,135,136,126,136,135,81,138,34,103,91,125,133,119,107,135,129,98,127,137,112,110,133,103,58,120,137,90,101,60,80,139,126,135,116,102,137,138,131,36,108,137,88,91,119,120,136,107,117,36,123,62,108,31,97,32,111,100,45,87,133,138,60,136,92,139,122,105,140,50,140,133,128,137,99,133,21,93,100,106,140,102,86,136,133,74,74,98,140,118,133,138,135,74,128,87,139,77,112,143,74,123,137,135,112,112,112,136,89,112,62,135,113,112,136,118,126,91,89,112,100,112,91,76,138,91,136,114,107,140,124,138,109,130,140,138,142,138,139,89,138,90,129,138,88,138,114,107,133,137,102,136,133,112,138,111,89,143,135,107,109,98,94,121,68,58,132,136,139,46,56,60,46,128,98,79,34,114,48,29,140,124,64,27,110,59,98,60,72,140,136,131,77,86,114,108,131,137,137,71,70,115,100,90,129,127,92,138,111,96,135,138,92,98,88,96,101,54,73,113,133,54,136,69,106,76,135,53,83,129,78,132,41,135,138,133,138,139,110,85,123,135,62,121,138,89,46,109,117,44,94,128,136,128,130,44,126,123,143,93,69,46,66,73,68,118,128,18,133,110,53,80,113,45,117,138,130,55,42,98,63,59,128,52,125,129,130,52,83,55,140,93,108,137,142,117,141,113,108,102,57,88,120,139,138,91,137,92,120,136,111,127,123,138,135,87,73,132,75,142,109,130,136,137,138,141,25,64,92,137,137,137,138,136,125,132,136,82,116,121,136,60,131,83,87,121,104,87,108,90,61,131,82,131,136,135,93,82,88,85,90,79,64,128,85,90,139,134,123,134,99,137,75,82,93,91,85,106,83,63,137,136,53,108,124,82,78,104,57,102,51,95,109,45,27,136,33,122,41,73,131,45,142,116,61,114,80,109,70,45,81,136,66,108,79,84,137,104,136,136,139,88,136,61,139,64,95,37,119,121,40,67,114,119,144,138,110,140,37,128,101,95,132,80,101,132,119,86,105,53,49,62,101,39,108,64,22,47,27,52,73,45,50,43,77,99,45,75,137,58,82,69,42,73,81,77,45,78,51,77,84,105,64,66,27,7,35,26,41,35,119,125,19,46,54,136,39,88,96,121,90,54,104,33,37,96,73,105,52,27,128,130,140,55,75,137,79,140,32,33,142,97,137,88,43,49,63,142,65,44,104,41,43,94,74,42,129,100,139,88,58,111,139,130,142,127,48,27,98,40,132,70,68,60,122,142,139,91,136,84,96,116,142,93,61,106,135,135,106,52,96,86,137,132,117,57,140,122,120,78,71,123,137,136,127,106,38,129,99,102,52,139,55,61,56,62,82,140,62,46,127,71,138,127,135,80,115,133,97,26,95,140,126,27,91,140,74,122,107,136,113,135,34,58,39,128,146,133,44,121,136,121,140,52,131,125,120,113,116,139,67,136,47,118,104,63,138,134,115,111,97,109,88,40,118,102,115,43,95,141,137,138,56,137,131,69,139,68,101,80,34,136,84,141,136,122,41,44,132,126,140,92,66,41,142,65,76,68,30,24,100,83,140,120,41,35,50,55,108,49,80,136,17,87,118,97,96,111,67,70,35,24,99,70,51,139,107,134,39,109,112,81,44,110,77,49,32,103,134,144,103,132,69,139,138,142,143,142,133,133,139,62,130,94,31,138,131,96,31,138,108,138,53,144,139,133,92,118,135,139,73,104,130,126,133,140,140,122,122,98,34,122,102,124,101,102,102,134,124,104,131,79,138,98,116,123,84,86,60,116,76,83,102,136,105,136,136,110,114,57,136,136,92,84,72,94,138,46,138,123,62,107,85,136,124,63,102,133,112,130,121,57,97,132,105,136,140,89,80,137,119,75,39,140,140,134,143,136,135,142,87,141,124,132,139,87,88,132,94,132,137,132,132,101,132,139,101,108,73,132,140,132,132,132,136,99,132,132,100,59,136,117,136,105,136,141,101,136,135,46,79,105,105,85,121,56,59,36,138,117,131,138,53,85,139,56,83,137,132,131,138,139,118,113,148,83,92,33,69,137,79,135,43,127,111,53,138,60,89,29,138,139,69,139,131,86,138,116,75,51,63,117,74,115,78,73,138,56,88,129,58,107,114,123,108,75,115,64,137,83,43,105,35,131,91,137,139,124,77,99,108,68,131,99,104,138,103,85,118,140,84,136,141,140,104,146,95,123,142,119,95,112,92,142,63,140,132,44,134,95,113,62,83,98,119,72,140,140,91,136,114,121,91,95,97,139,133,129,132,91,103,130,56,140,83,81,140,44,118,129,142,135,135,107,135,140,35,96,115,116,128,141,107,73,130,72,127,82,136,110,137,43,63,101,63,136,107,146,92,100,116,128,63,136,106,136,110,63,100,136,112,85,136,101,124,136,83,135,121,136,106,102,108,99,124,128,139,79,128,135,63,130,117,138,96,83,126,85,114,92,73,136,124,133,54,132,132,109,117,13,65,111,131,56,137,69,111,125,90,100,79,140,131,139,138,103,85,109,139,138,124,65,120,72,95,78,104,140,108,121,138,136,89,124,132,131,115,137,83,128,74,112,34,132,129,42,102,32,139,79,68,114,130,137,96,81,100,143,104,139,73,120,128,45,98,119,139,137,124,97,80,66,112,17,46,143,138,121,78,25,135,126,139,78,96,106,137,130,26,37,94,92,135,106,106,134,106,86,102,135,34,113,84,120,142,135,133,106,129,116,105,125,111,92,106,117,116,136,64,137,136,92,140,67,102,86,47,133,134,55,86,108,108,136,73,84,62,136,61,110,136,39,51,138,114,38,87,66,51,99,126,57,59,91,101,58,62,133,101,60,78,135,97,58,87,90,32,139,64,99,99,62,73,55,82,108,134,101,67,143,89,83,99,126,124,122,118,101,100,100,105,99,136,95,115,100,108,118,107,79,94,101,139,107,118,85,135,139,119,124,139,114,99,139,107,125,101,113,111,139,118,149,137,136,87,136,139,136,139,136,39,136,133,70,87,114,109,32,65,136,54,95,78,34,25,70,129,136,67,116,139,131,135,135,140,135,135,81,135,117,135,138,135,103,139,135,138,143,136,68,136,108,138,135,135,140,122,140,135,137,120,101,141,102,52,77,40,109,135,56,139,134,42,64,53,125,113,123,100,102,126,87,104,42,52,34,133,139,60,109,124,95,143,122,93,88,133,106,89,136,132,134,132,139,131,141,136,133,134,92,96,141,114,134,134,134,134,76,116,136,139,89,107,71,136,79,113,140,123,136,113,112,108,129,99,135,55,53,118,140,79,77,135,62,134,76,140,115,106,56,136,110,135,93,48,26,140,85,123,137,77,103,130,55,58,121,72,140,132,78,140,132,117,42,115,89,93,23,90,57,60,63,43,46,90,49,145,36,45,45,43,127,65,53,136,116,90,132,137,97,47,139,111,123,37,81,135,49,136,55,103,143,135,114,114,118,76,136,98,38,80,81,55,87,136,65,121,90,101,62,105,112,138,81,79,132,31,133,136,102,32,138,138,134,50,138,100,131,53,138,61,102,28,76,65,96,100,51,128,114,126,52,139,39,138,131,38,139,135,27,116,98,45,59,134,122,102,104,124,133,140,102,50,72,95,125,65,98,104,105,73,25,94,135,118,140,94,134,62,120,129,87,133,138,138,94,128,76,133,117,135,111,121,140,94,117,135,77,93,140,135,110,140,136,135,135,136,87,53,110,106,99,135,135,135,97,76,20,80,135,135,23,142,19,107,72,123,133,86,29,73,137,48,114,105,128,69,20,27,62,34,91,74,54,132,51,92,108,109,81,22,117,38,117,117,126,117,139,38,119,70,85,136,95,56,141,57,140,69,111,72,93,99,91,101,137,89,123,132,144,135,103,114,64,120,89,128,136,39,139,138,100,103,83,69,134,139,92,76,139,17,139,90,139,104,108,101,135,125,140,138,137,138,59,86,137,135,136,139,133,113,52,97,136,110,140,111,139,120,102,135,119,59,137,139,124,139,112,127,102,133,75,140,107,84,134,107,76,91,95,136,111,68,93,136,124,134,124,132,136,131,139,104,103,93,122,94,142,132,90,134,96,137,139,101,133,137,137,88,113,117,138,109,136,134,131,136,60,141,137,132,141,130,142,104,127,138,138,126,141,57,126,126,123,140,126,123,139,106,56,117,123,102,126,123,34,100,84,51,130,103,102,130,64,123,137,98,83,100,123,126,126,126,102,111,100,101,103,121,66,68,120,70,134,50,134,74,120,138,139,140,110,138,114,113,66,81,69,137,87,90,116,44,66,93,114,87,95,123,79,78,102,88,121,138,116,138,44,85,88,96,138,24,117,112,43,99,136,80,134,130,127,138,34,101,136,127,133,137,136,93,138,100,137,131,92,112,114,95,136,85,75,138,87,33,114,83,118,82,114,137,73,136,86,136,122,87,77,139,74,107,119,137,139,137,134,137,129,80,136,132,131,136,135,127,111,112,105,104,142,126,92,137,138,73,98,140,114,100,95,54,143,78,124,84,131,99,143,62,96,111,68,98,43,107,33,121,143,126,108,25,143,26,76,130,49,94,72,138,143,65,29,143,78,24,44,57,111,87,139,125,133,46,146,79,138,137,79,92,132,76,139,137,108,79,76,36,52,100,76,132,129,24,131,137,115,62,75,136,137,139,139,103,135,84,131,92,101,98,73,113,61,116,137,116,76,97,128,71,121,92,58,139,94,140,95,139,139,124,26,113,89,132,120,139,132,76,126,139,134,126,31,82,119,116,135,136,116,132,136,130,130,140,124,104,75,93,109,134,135,135,113,113,140,112,61,138,137,113,108,132,130,135,47,87,138,94,138,44,72,92,141,140,136,87,123,139,63,139,92,119,137,124,105,97,140,107,138,115,67,140,135,73,94,83,92,93,141,132,79,105,136,79,134,64,98,79,48,110,82,90,73,136,69,136,93,137,74,101,99,136,98,118,136,52,79,136,136,101,90,61,16,136,136,79,69,136,136,79,103,136,123,91,135,126,111,136,129,107,84,135,136,73,48,106,112,139,53,45,112,95,85,73,129,111,115,76,99,138,58,115,134,83,124,81,117,129,134,83,140,124,139,140,102,124,59,22,129,130,68,9,76,68,8,79,125,97,33,46,108,47,38,103,26,33,138,36,40,72,25,97,32,64,130,102,80,126,130,135,13,80,36,83,137,88,128,61,81,132,138,64,140,132,120,64,37,140,138,136,114,38,66,98,99,32,38,140,97,90,72,139,45,138,69,35,111,138,105,140,20,134,118,95,134,43,124,31,78,46,79,42,50,10,72,36,135,127,138,70,52,35,30,64,136,48,49,122,110,115,78,77,30,95,80,104,23,57,88,76,115,113,121,63,135,134,67,120,104,136,46,55,137,76,116,55,126,141,133,116,138,123,103,54,51,62,138,39,50,111,101,116,107,97,132,68,140,132,139,104,140,137,130,112,102,87,124,78,130,103,89,100,116,112,117,108,92,134,134,122,143,105,134,139,139,109,44,87,138,37,97,48,45,45,71,64,139,110,135,124,129,27,90,140,135,50,134,135,102,69,124,36,87,115,130,135,135,104,105,109,82,71,94,106,47,42,47,33,130,139,70,122,135,127,116,22,80,31,140,105,60,33,130,133,133,128,135,30,39,139,131,139,115,136,139,88,85,139,139,85,101,139,126,131,77,139,22,139,139,68,145,126,138,137,139,114,93,139,88,128,139,139,139,81,139,139,116,114,136,139,144,80,80,130,139,131,134,36,65,116,107,85,136,138,80,86,123,100,117,76,140,113,46,105,84,135,118,52,136,42,106,135,77,40,90,137,139,143,115,137,134,136,140,129,65,126,110,55,143,135,137,135,134,117,96,91,136,81,96,85,135,139,105,135,99,97,112,137,89,112,21,122,125,137,135,101,107,98,53,72,128,91,42,94,123,70,72,138,137,137,134,70,97,62,138,136,135,138,72,139,89,87,137,111,97,128,82,92,138,96,110,139,78,129,104,53,135,90,101,135,103,109,128,125,140,126,40,89,60,127,72,140,123,102,44,83,80,140,96,113,133,113,139,29,134,33,39,113,32,36,105,84,134,142,131,67,73,29,130,137,101,114,49,134,138,97,98,79,111,84,74,49,94,82,98,139,140,97,137,142,39,125,118,88,33,123,98,132,103,128,138,113,134,85,65,107,51,136,110,129,120,90,56,136,143,112,80,144,140,132,138,35,140,57,90,92,58,112,88,82,51,84,137,101,132,124,140,63,56,96,137,138,142,82,115,108,76,62,19,128,81,68,138,121,126,49,101,84,82,106,76,139,140,136,125,123,97,71,73,73,92,110,111,131,93,128,91,105,138,133,65,65,121,70,78,117,133,78,124,133,74,135,70,137,70,139,51,140,86,51,65,83,64,117,138,65,125,78,117,133,70,78,112,135,136,137,76,79,86,140,91,100,33,141,138,121,66,101,131,128,115,87,115,105,36,113,120,119,136,34,94,111,121,111,131,137,49,97,114,100,114,100,120,70,138,120,114,107,107,130,38,58,78,138,133,80,132,120,114,100,114,130,107,114,107,117,138,100,71,50,55,124,114,123,114,88,137,135,139,96,119,87,122,122,87,109,136,133,106,136,84,97,132,119,118,101,82,42,114,76,109,37,135,127,88,101,134,122,106,138,128,108,105,108,104,69,132,70,108,108,69,100,117,108,108,76,133,79,113,84,103,69,103,94,88,94,109,109,114,76,108,87,102,73,109,119,119,119,119,120,119,119,73,119,119,85,147,119,119,119,130,119,119,91,117,95,119,138,119,119,73,102,73,121,119,116,140,70,120,111,92,23,89,117,83,44,136,59,85,104,130,83,110,83,69,136,137,114,112,67,125,71,67,137,43,140,139,126,126,140,127,133,113,105,57,126,126,138,88,130,97,133,139,131,81,136,92,140,50,126,126,140,114,115,139,143,136,139,103,126,126,140,136,66,33,93,134,45,134,40,42,56,139,86,67,93,55,27,17,75,122,106,63,26,33,71,87,139,85,137,141,137,136,134,56,139,21,132,24,140,75,139,143,72,66,116,136,73,132,74,131,66,46,115,105,68,90,120,131,72,110,135,28,139,109,137,127,117,120,138,135,136,90,127,48,135,50,141,111,129,107,128,120,130,50,133,105,138,98,133,116,83,138,107,94,124,84,131,78,84,79,134,87,127,135,85,46,70,133,122,120,88,115,85,95,93,142,98,84,88,123,133,140,128,113,93,48,98,126,133,89,76,88,122,87,61,53,80,115,138,98,82,127,98,139,80,74,137,58,108,130,126,134,137,101,75,139,79,138,129,139,122,61,134,111,95,138,128,127,144,142,40,110,138,139,141,140,136,133,63,138,136,110,138,77,110,141,126,67,77,39,58,34,145,88,136,50,139,88,133,54,124,137,136,138,81,140,71,85,117,111,139,96,119,137,133,90,115,61,68,140,142,76,74,140,67,131,46,114,67,82,139,114,129,115,54,67,116,22,40,80,132,48,139,87,16,55,104,73,11,118,53,139,138,139,35,75,76,126,88,139,103,44,103,130,145,105,103,140,90,75,92,29,100,74,103,123,120,107,100,71,55,66,139,123,73,28,109,96,130,101,105,134,136,78,60,133,136,134,135,139,140,110,132,123,139,67,138,124,90,131,137,83,138,133,152,135,137,136,58,131,132,136,68,134,82,120,107,52,142,127,139,39,140,86,100,68,133,115,137,87,134,76,135,92,135,142,143,134,135,107,44,96,102,126,110,121,137,102,40,136,119,81,126,111,140,110,136,130,47,139,135,98,77,132,48,125,71,137,81,49,139,53,85,76,72,108,51,87,62,100,135,137,86,90,132,123,134,129,138,137,118,113,120,7,27,58,137,18,118,140,135,76,61,85,117,131,113,139,74,106,143,137,129,134,116,62,121,62,115,44,87,126,65,126,116,19,41,135,135,32,85,76,145,126,70,129,116,73,139,115,83,126,90,66,87,135,142,110,60,38,92,57,127,136,68,39,135,87,127,112,136,138,133,45,104,92,76,24,109,130,91,43,46,140,8,94,81,119,78,132,88,122,138,140,140,108,109,59,94,136,134,108,98,139,111,114,139,142,135,140,111,110,138,111,111,140,90,139,137,136,132,134,120,63,60,114,56,106,42,69,100,103,103,62,48,117,49,110,59,34,135,49,77,33,114,95,117,94,25,61,42,76,41,26,45,74,99,34,127,52,64,104,134,75,96,106,118,43,72,139,137,140,112,82,116,138,97,88,116,115,105,130,119,74,51,115,104,142,111,137,135,115,72,129,133,118,106,145,132,135,126,81,71,135,89,142,89,84,124,144,137,115,89,126,124,116,97,131,133,88,136,89,89,129,144,139,120,137,7,140,87,97,92,136,109,137,140,54,95,64,113,133,137,140,79,143,89,72,135,99,51,55,119,96,113,138,96,113,121,82,111,130,98,62,136,140,144,140,64,139,137,70,138,53,80,98,110,60,86,28,119,46,81,76,102,138,135,82,121,126,110,91,139,110,135,64,46,11,87,69,27,128,106,140,101,84,92,84,139,127,122,128,30,139,84,34,80,50,61,83,96,84,104,139,58,36,137,117,82,95,125,143,86,135,135,76,36,76,79,96,44,78,76,139,128,138,138,77,95,124,72,95,135,139,102,137,98,135,95,101,85,85,85,85,85,94,140,86,134,136,135,97,85,96,136,117,136,132,139,92,38,79,85,85,92,91,111,91,139,85,95,75,101,136,136,136,87,119,136,120,136,139,101,136,136,136,136,136,136,136,136,136,136,136,79,136,124,136,136,136,136,82,136,136,98,136,136,136,136,138,136,133,129,34,113,104,125,88,136,108,94,63,120,86,43,73,86,88,71,113,95,71,84,88,146,88,133,59,91,88,88,65,109,103,63,108,128,87,139,134,16,43,71,133,130,66,76,128,48,46,136,116,91,114,68,96,94,78,121,92,88,81,147,131,134,22,138,61,133,136,111,75,102,132,93,32,25,132,60,88,43,78,71,55,23,98,130,78,71,66,72,131,95,93,63,59,117,114,49,89,100,85,66,27,124,103,66,62,65,103,113,136,139,73,137,100,138,141,111,134,129,76,113,120,136,90,138,102,135,137,104,125,62,116,83,98,139,105,112,95,128,110,138,128,85,136,127,135,67,109,116,113,121,90,116,80,136,113,80,67,68,122,136,136,84,78,106,140,67,125,136,135,136,67,67,91,113,99,67,92,67,124,133,137,124,136,83,136,114,81,137,69,136,137,63,76,82,133,96,124,137,124,136,115,141,138,116,88,131,136,137,142,99,95,124,132,124,136,85,101,82,137,137,142,130,133,103,130,117,50,115,137,94,112,118,136,88,119,118,140,97,100,102,95,112,136,111,25,140,45,68,136,128,29,136,119,112,71,66,70,108,78,94,100,137,108,94,94,135,122,94,94,108,108,108,138,108,108,94,45,94,94,108,100,93,109,98,94,94,94,118,108,96,108,94,105,142,82,119,116,139,101,135,59,86,89,123,136,62,136,135,83,139,67,92,131,102,89,86,139,144,121,131,141,59,122,121,79,139,89,140,140,87,66,113,75,137,137,113,112,48,59,105,105,104,82,97,58,75,135,79,71,96,113,136,107,87,60,138,106,113,110,125,45,60,137,61,78,89,65,112,140,132,107,113,116,59,69,107,123,67,62,79,130,143,124,129,140,60,136,136,136,136,140,136,136,71,137,128,136,89,136,136,136,136,131,136,138,136,129,139,141,136,136,136,113,136,136,96,137,77,140,137,136,135,66,26,134,120,122,92,91,96,135,44,75,128,141,95,136,117,91,95,78,116,113,141,138,142,105,135,124,135,100,66,138,137,59,135,137,89,43,88,73,109,59,143,109,117,76,72,94,128,144,136,87,139,28,55,76,139,67,76,136,137,137,122,82,75,134,117,138,143,99,138,113,138,138,145,138,95,138,96,142,114,80,95,131,92,127,96,138,31,86,101,129,95,92,138,82,95,122,83,22,47,138,41,75,72,25,117,101,110,38,85,84,51,63,83,83,97,36,112,78,43,32,109,40,102,54,99,94,54,141,74,114,31,42,81,91,91,139,91,66,91,91,91,91,91,138,22,91,91,91,91,61,140,91,91,91,91,91,87,91,91,46,91,91,91,97,91,44,65,90,91,59,78,139,65,79,133,139,106,119,52,66,85,130,87,79,110,81,128,118,134,104,114,127,71,86,53,50,140,87,89,39,53,50,134,47,87,63,133,52,32,24,44,109,59,58,57,68,134,60,25,19,63,117,123,117,80,66,59,47,73,98,33,138,37,55,40,58,72,143,47,56,26,50,119,35,20,32,133,135,80,78,60,47,31,31,77,23,70,74,47,77,97,48,139,134,77,54,120,59,118,64,113,83,11,47,46,136,92,134,76,123,118,124,136,84,125,118,101,101,88,121,116,122,118,63,130,101,99,101,72,139,141,83,78,136,130,139,90,115,73,73,85,115,68,147,78,92,138,90,129,81,129,129,82,136,81,77,95,67,32,97,141,136,138,88,68,71,128,76,68,137,33,109,112,81,109,136,129,101,129,86,137,129,96,91,130,67,100,76,35,104,129,98,72,138,95,112,139,78,65,130,130,129,109,104,131,109,129,70,36,102,129,41,109,80,103,140,20,47,98,100,40,142,128,129,86,79,119,52,140,113,140,87,54,61,97,130,136,136,72,143,50,69,60,45,48,45,126,85,128,44,81,106,64,134,77,141,104,93,26,89,70,14,35,127,116,43,118,111,37,128,130,29,62,90,111,129,79,89,81,35,75,120,61,49,47,22,44,134,92,95,54,100,18,78,33,108,84,38,34,137,123,72,93,41,35,110,96,35,31,124,68,15,62,136,93,48,78,70,139,140,140,116,50,133,80,139,97,116,63,111,112,86,64,134,116,55,131,134,135,121,132,126,146,137,137,15,136,128,58,33,124,90,138,59,115,89,79,137,79,77,106,69,101,141,14,44,135,132,101,63,20,134,47,140,70,97,93,125,79,131,98,93,126,64,138,144,102,100,54,135,51,98,62,55,105,62,63,63,63,111,57,56,70,91,139,57,77,138,140,100,80,56,63,140,81,102,100,138,136,136,125,91,118,121,117,101,116,139,140,140,136,94,136,135,132,134,131,52,128,138,137,133,134,94,136,115,139,138,132,123,140,130,130,140,84,130,107,124,135,20,140,130,138,120,140,140,120,114,125,100,100,100,130,117,107,99,117,100,125,140,139,122,117,86,85,135,105,76,77,136,136,136,89,91,137,136,57,92,140,86,105,138,109,108,136,63,86,136,134,121,136,136,67,105,137,139,96,141,140,96,47,77,103,100,81,120,140,132,49,98,128,81,81,138,134,135,77,141,67,137,87,135,81,127,136,123,79,139,70,89,107,81,139,78,134,72,50,94,123,91,103,147,53,134,59,138,126,90,139,54,70,109,38,53,138,139,138,140,125,44,52,53,133,140,57,132,106,136,96,68,96,95,138,67,104,34,53,118,77,127,27,81,143,61,124,144,67,134,99,12,126,129,49,120,93,34,100,126,119,85,138,123,130,41,99,63,138,132,132,109,70,66,79,101,80,62,130,44,67,140,136,71,147,131,139,127,126,139,79,57,132,93,43,86,125,132,136,71,142,59,85,25,138,135,118,74,127,122,99,85,116,100,138,141,97,137,131,144,59,90,69,120,93,137,120,58,105,93,140,120,114,79,136,49,121,64,85,143,110,94,90,102,109,102,53,120,134,120,140,132,120,90,100,120,100,87,43,30,139,101,137,101,116,78,90,139,110,28,52,102,130,139,76,70,140,142,131,93,100,133,48,140,138,133,100,124,137,85,138,80,81,128,139,53,112,59,86,60,31,82,25,72,107,38,116,27,139,71,62,40,102,51,51,135,116,51,134,137,73,33,85,43,45,63,16,90,34,102,146,65,137,31,10,58,91,103,66,51,136,119,99,136,127,89,91,78,140,134,112,134,136,124,138,91,111,138,78,100,118,77,122,134,120,63,104,75,29,136,75,33,82,92,39,90,97,140,130,67,118,130,87,81,127,40,91,57,137,84,104,104,127,125,134,26,89,141,45,87,56,44,91,114,109,101,75,78,81,59,142,137,128,137,81,65,125,106,109,130,83,137,120,140,138,138,138,49,137,54,137,124,139,128,137,137,137,137,142,60,50,142,39,84,95,136,135,134,53,137,77,113,137,54,132,130,137,77,95,136,77,28,112,136,101,51,136,91,135,136,136,77,77,133,105,120,136,140,123,83,49,109,136,133,96,26,68,122,139,102,138,91,68,126,43,140,136,84,124,139,106,117,137,112,110,116,73,19,71,83,72,128,142,34,30,108,87,60,25,111,44,28,92,56,133,94,135,121,123,86,135,68,136,52,89,74,69,63,84,77,88,136,85,108,88,135,12,44,50,99,87,122,49,85,112,147,71,46,75,133,81,129,92,107,70,64,126,132,80,140,58,69,18,98,148,146,73,29,69,89,133,43,125,101,96,133,23,121,80,119,35,38,119,67,29,138,87,140,86,122,96,97,28,138,18,34,53,136,105,148,139,67,84,136,75,39,55,121,52,136,81,139,128,111,93,62,131,54,34,123,100,69,91,138,49,96,117,57,34,122,29,137,122,91,127,131,136,140,134,128,136,137,136,136,139,136,105,136,128,65,121,91,136,137,136,136,53,136,77,138,140,84,80,59,69,121,140,69,98,46,37,136,136,65,140,79,129,41,82,98,138,134,125,75,139,103,138,79,79,67,138,100,66,99,86,80,80,117,122,135,139,122,136,132,80,77,87,117,129,70,79,137,134,55,74,134,134,136,135,104,139,118,119,138,106,133,66,139,90,135,140,103,78,136,106,135,74,60,133,136,104,139,78,132,126,117,126,115,135,142,106,128,129,132,110,135,135,82,132,65,132,143,113,139,30,120,67,77,38,92,135,113,123,89,90,31,96,60,87,99,61,108,47,53,140,93,125,48,134,32,82,36,107,73,95,47,128,134,139,138,105,95,33,130,19,140,96,121,77,81,109,91,102,54,46,56,140,51,106,60,34,120,83,130,62,109,124,123,42,19,62,106,140,56,78,121,122,114,118,142,133,137,102,133,113,129,134,132,69,29,117,105,139,102,144,100,137,47,140,137,127,99,130,44,140,129,123,138,129,88,129,101,117,111,138,133,46,36,122,91,138,54,80,88,140,129,128,72,41,101,113,122,100,100,103,147,132,81,110,100,68,139,18,139,108,140,112,68,107,51,143,62,139,108,88,125,138,137,137,144,76,119,70,143,87,137,139,46,73,122,133,120,36,81,125,107,142,60,78,122,37,140,69,137,136,78,89,136,135,140,78,140,131,38,120,135,84,80,105,140,100,72,133,117,92,96,135,112,139,128,51,125,136,75,136,100,106,130,94,138,105,95,88,40,85,52,125,115,89,137,51,90,100,102,95,77,84,89,84,113,73,136,95,140,142,75,69,96,99,71,136,98,132,140,92,136,107,136,81,58,134,138,134,88,69,136,145,117,132,68,136,138,88,95,69,52,128,136,83,99,96,139,134,74,134,58,135,140,136,105,134,139,91,134,133,68,71,140,88,140,119,139,80,128,134,120,44,18,137,139,73,66,84,114,123,120,106,52,101,146,95,92,128,50,135,105,123,76,29,12,107,79,69,85,63,102,101,140,84,124,126,136,123,45,120,33,68,74,54,140,85,121,110,114,46,130,78,85,136,56,138,45,101,41,136,103,136,105,136,139,136,136,139,137,92,136,136,136,136,136,60,136,102,136,137,136,137,136,136,84,92,137,60,136,109,136,60,136,136,136,136,83,136,109,129,93,100,120,87,97,46,70,94,118,112,46,70,40,65,38,29,26,25,117,48,96,17,137,91,88,70,49,80,63,51,49,107,48,107,93,104,80,130,127,69,97,18,132,14,145,79,136,60,91,107,134,122,114,131,92,99,65,136,136,114,121,134,83,125,65,137,94],\"type\":\"histogram\"},{\"name\":\"Test\",\"nbinsx\":50,\"opacity\":0.5,\"x\":[34,64,96,40,45,34,72,17,16,9,21,26,22,9,8,120,54,109,114,94,44,67,138,137,44,139,80,143,72,115,137,31,135,91,99,134,112,139,99,136,103,115,73,127,119,74,149,138,135,138,59,132,128,138,34,73,80,72,101,34,129,147,57,133,134,85,132,83,77,130,56,129,136,137,137,87,76,103,106,140,82,98,81,77,110,137,141,116,136,136,130,139,76,71,90,124,76,139,123,57,53,54,79,95,134,90,139,65,94,139,139,77,126,60,139,139,139,138,138,90,139,139,139,139,73,129,133,137,122,18,119,58,113,124,113,109,77,130,89,133,48,133,49,60,44,110,71,135,63,138,84,103,103,126,89,98,89,104,81,103,103,103,100,131,103,102,91,85,83,99,99,139,139,119,118,76,90,138,87,17,85,105,136,139,138,136,73,51,89,120,44,140,107,75,30,28,90,109,68,86,120,29,106,103,78,141,88,106,95,100,132,146,137,72,136,131,133,122,122,93,122,122,130,117,99,122,48,122,117,113,62,105,136,129,88,111,123,117,125,44,117,101,132,99,127,53,84,63,67,136,38,98,132,133,101,138,89,112,112,111,135,141,101,138,114,121,83,86,122,96,96,127,150,119,61,90,62,136,112,151,53,138,59,151,125,26,26,133,144,65,67,49,29,128,106,20,60,34,71,53,97,34,48,137,68,122,15,134,127,128,95,56,136,117,135,127,127,135,92,97,67,94,123,53,112,102,132,135,119,45,53,47,78,27,66,27,62,28,87,28,38,122,136,60,133,22,92,125,140,72,128,88,78,35,86,136,91,70,24,133,116,106,138,90,90,138,139,33,23,93,59,132,62,27,139,42,132,133,90,57,129,139,117,50,40,58,69,67,57,77,134,127,112,115,114,120,117,106,25,44,40,65,79,94,55,136,75,86,98,135,128,93,138,136,87,75,76,136,32,81,141,122,73,67,95,122,97,139,112,128,133,139,139,68,101,139,139,131,138,116,129,69,116,139,90,140,74,108,142,37,125,134,89,75,37,26,53,109,128,106,131,69,122,46,140,136,139,123,125,126,135,136,138,139,31,140,140,96,110,93,73,46,74,131,42,131,133,49,79,140,138,134,131,140,93,143,51,65,49,126,96,81,102,82,61,114,113,99,136,79,71,96,81,88,136,128,138,83,126,129,120,106,79,104,134,135,124,118,63,142,149,88,47,130,151,69,133,133,87,132,103,146,130,138,69,139,108,139,144,142,120,82,96,144,101,139,137,69,143,49,71,121,135,94,135,81,94,128,97,133,79,87,137,124,97,134,141,140,49,137,140,132,134,28,78,139,31,87,88,64,114,80,140,47,88,97,139,141,142,109,103,71,69,104,135,124,70,129,124,63,84,69,129,103,119,135,115,112,53,89,72,136,114,114,111,130,144,132,89,126,135,126,35,134,31,135,112,139,131,113,95,58,108,144,19,144,17,134,90,133,75,43,83,116,91,116,110,96,91,137,136,57,137,76,139,49,127,126,112,126,137,138,118,74,131,135,41,124,139,98,121,87,138,129,118,69,88,112,127,116,34,88,134,117,136,111,57,28,39,67,136,75,108,134,130,75,100,133,92,78,62,54,119,92,96,39,113,88,137,103,111,125,76,137,112,128,86,89,111,73,44,122,138,141,69,42,131,140,113,119,74,122,81,97,111,62,61,77,13,57,139,90,142,128,80,137,135,141,132,22,79,136,138,90,100,119,85,131,98,103,21,69,96,73,64,107,113,133,117,65,5,47,91,89,106,109,131,81,78,120,108,110,139,79,73,127,54,128,136,51,44,136,101,57,89,134,136,126,141,74,48,46,31,60,110,53,131,112,42,46,139,104,134,129,135,101,117,117,35,55,23,39,115,81,132,23,66,21,127,113,66,125,142,84,47,78,76,84,78,54,81,70,30,136,59,72,132,64,31,140,73,123,70,114,97,64,104,138,121,121,123,98,114,133,137,52,68,66,36,47,115,50,138,136,138,100,131,68,82,59,110,139,140,144,34,133,29,55,65,91,75,115,35,52,94,94,130,108,87,145,131,67,38,126,57,83,140,139,40,115,125,86,37,35,54,136,68,87,31,104,31,134,76,139,131,128,88,144,87,133,73,81,87,136,138,85,96,122,136,94,120,130,136,87,146,140,130,106,124,46,95,96,101,144,132,132,140,132,60,132,132,96,132,132,44,132,132,132,94,131,105,128,138,109,87,131,95,105,125,136,111,139,98,137,92,63,108,123,110,96,111,134,47,138,132,138,37,109,137,98,22,113,126,99,43,145,39,63,32,138,70,122,86,137,70,90,140,87,137,137,115,95,117,76,144,136,125,137,139,74,135,95,143,139,70,134,141,130,138,138,111,70,130,98,138,136,111,60,140,122,135,70,135,140,107,89,136,137,128,136,106,135,136,68,63,117,71,130,122,80,50,113,139,132,85,74,133,140,126,90,86,51,17,126,67,95,117,45,45,121,116,115,62,112,131,139,98,109,136,45,118,139,55,47,77,81,111,70,96,140,136,106,86,126,135,135,80,105,75,139,131,104,133,70,140,56,32,136,131,143,117,84,71,136,136,119,136,70,120,117,121,137,80,128,61,81,138,68,101,86,146,112,116,128,138,138,125,139,127,108,50,107,139,139,139,119,107,113,118,121,101,114,92,136,53,36,51,53,77,136,108,136,139,135,128,136,140,100,131,50,68,50,116,99,132,140,120,121,92,72,70,127,136,133,137,135,135,126,137,140,69,113,34,107,139,142,32,68,137,105,124,135,120,134,134,137,136,138,131,92,106,136,9,101,134,122,92,82,82,105,118,26,55,127,25,65,136,83,120,63,28,133,38,96,28,35,22,97,39,69,77,23,130,50,76,46,32,91,54,136,101,136,135,54,86,51,138,137,136,74,34,61,136,136,57,73,73,65,138,138,69,126,126,138,140,34,75,85,62,100,55,106,132,101,76,77,139,102,86,47,104,135,76,41,108,119,138,127,135,86,87,49,45,77,62,127,117,24,83,88,82,86,99,78,101,114,140,82,138,117,134,29,97,129,140,109,58,52,139,57,122,101,37,125,39,137,136,145,138,96,108,138,139,137,38,85,72,49,137,78,102,116,141,139,104,106,110,131,127,102,116,134,136,101,101,138,139,92,124,88,139,142,82,104,138,135,139,140,102,135,97,61,100,68,123,118,102,102,95,138,130,105,126,106,100,63,94,115,143,138,104,76,120,46,80,93,134,81,135,135,84,134,138,127,58,98,121,115,71,136,93,80,91,90,142,83,81,114,114,124,113,128,103,87,131,43,35,135,29,20,124,111,47,46,109,53,85,97,111,144,71,137,66,65,136,137,133,114,47,137,138,111,62,96,113,139,139,135,136,133,81,57,130,140,131,107,62,137,138,136,140,88,102,136,134,136,135,77,139,126,113,130,115,122,92,139,74,47,136,138,135,138,105,94,70,108,136,136,136,122,36,110,79,97,136,137,91,107,140,138,72,40,71,84,22,128,105,137,14,90,132,22,143,31,137,105,137,137,86,28,139,136,45,56,61,14,58,139,106,90,90,112,45,136,40,91,97,132,116,141,97,127,121,86,87,81,130,136,95,75,106,132,129,133,88,82,98,135,137,137,122,103,130,107,125,133,129,134,135,108,142,129,121,46,114,107,137,111,139,40,29,49,58,68,91,114,140,96,128,132,132,73,136,139,25,119,53,78,88,85,139,65,140,140,81,139,139,139,84,139,139,136,135,139,139,140,136,89,138,74,86,93,58,62,96,98,75,142,140,135,137,137,45,143,117,122,31,117,140,119,135,129,61,88,110,99,138,99,137,76,70,43,77,104,91,141,139,139,72,103,138,136,89,124,70,140,125,132,87,117,136,113,24,143,137,66,64,134,15,83,49,92,61,88,108,139,92,94,126,139,67,93,78,93,58,113,123,137,135,137,142,135,138,132,142,147,124,95,131,121,75,99,123,99,76,91,56,76,106,34,85,75,133,122,133,70,70,133,65,135,140,133,71,133,129,139,66,103,127,130,138,80,46,134,115,136,94,87,108,118,139,140,78,66,99,100,127,107,140,139,138,79,122,114,135,139,114,90,139,114,96,133,79,97,6,97,97,129,85,87,78,108,140,80,101,99,70,138,108,136,103,116,106,116,108,123,141,119,73,78,119,119,119,119,120,73,93,59,100,132,119,142,119,119,87,139,112,82,91,87,102,80,98,92,120,115,137,83,100,138,132,41,139,70,126,78,126,130,93,137,135,77,139,139,71,139,141,112,135,56,139,102,134,90,28,38,87,16,135,98,134,89,123,55,129,135,57,72,117,93,135,135,139,132,129,70,134,121,58,116,72,77,138,69,141,143,87,107,88,91,140,88,80,102,93,121,97,65,98,96,106,81,141,139,134,139,59,99,85,129,140,138,123,148,114,64,120,136,92,136,82,22,91,112,97,139,78,130,113,139,79,110,137,60,81,138,97,95,135,42,27,118,93,41,53,10,83,125,138,135,94,64,89,13,137,85,123,137,38,45,86,90,99,123,25,24,137,137,32,76,90,43,133,134,137,131,133,140,135,136,134,69,95,139,51,116,135,87,127,128,72,135,116,71,55,137,137,107,142,86,130,136,105,104,142,54,113,62,92,131,98,140,104,139,69,137,88,138,137,100,50,106,34,136,129,118,79,144,118,134,86,105,116,104,126,115,105,140,146,135,81,121,123,116,116,72,139,107,115,116,126,139,77,96,40,111,97,142,61,48,113,78,131,55,135,11,99,83,124,120,134,116,123,109,111,124,111,23,43,107,140,136,111,108,87,40,82,82,86,138,87,31,128,18,29,52,45,66,111,112,122,77,40,126,112,140,124,41,113,142,97,124,90,137,137,139,142,113,69,136,78,89,72,140,89,135,79,138,124,123,136,124,139,54,105,82,139,139,135,115,53,120,112,122,68,110,132,95,87,143,106,134,133,71,133,47,51,118,83,118,131,76,88,43,55,142,138,58,83,46,96,88,108,63,133,140,98,54,135,133,106,51,138,135,124,137,81,83,124,140,70,101,131,81,127,127,95,95,139,129,117,125,129,139,111,99,136,45,53,101,135,114,138,85,101,140,136,136,87,76,136,136,136,136,120,86,89,133,134,87,111,128,91,88,106,63,122,136,25,56,55,140,107,118,126,31,140,74,90,137,123,75,124,57,93,140,81,99,80,39,88,132,139,119,83,42,66,140,89,134,94,137,101,108,92,117,124,113,105,71,125,138,108,78,83,71,98,79,76,67,108,136,140,131,136,93,113,123,137,137,136,124,73,134,83,137,93,74,128,124,135,134,133,137,99,137,140,44,102,136,54,140,113,136,111,117,136,108,78,11,115,136,117,120,63,117,25,94,118,129,88,92,140,94,94,94,123,83,136,119,59,136,86,125,102,89,55,140,62,136,51,107,112,105,141,108,63,113,138,134,136,40,110,90,113,100,107,139,122,66,97,104,136,140,59,127,116,135,136,115,49,76,137,136,136,89,136,136,98,53,136,49,57,108,141,136,136,135,105,91,86,103,90,135,142,142,138,137,136,52,136,97,122,93,132,79,136,136,88,120,115,117,66,136,95,80,138,124,138,88,133,95,75,110,133,26,115,135,138,80,138,88,95,138,138,138,62,139,107,44,77,34,139,122,18,62,123,91,91,56,91,91,91,91,74,91,91,91,91,111,127,95,118,85,52,139,59,138,129,111,23,54,60,84,103,24,52,37,69,105,102,52,44,141,95,37,83,71,43,65,139,72,20,47,42,48,41,19,127,46,113,28,48,49,66,136,125,141,139,122,140,82,127,138,111,140,97,103,136,118,130,83,121,134,74,143,118,103,83,96,136,84,79,83,85,53,77,70,121,101,109,81,19,130,125,53,61,88,58,36,129,91,129,134,68,135,89,48,83,119,54,48,85,90,72,124,138,114,140,30,59,34,38,17,122,139,47,10,38,134,90,17,123,63,40,124,88,66,123,85,113,12,64,85,27,123,113,80,121,133,140,93,87,133,144,112,137,133,57,133,138,107,137,137,136,82,39,86,135,98,49,117,133,84,80,43,130,87,137,85,93,67,107,126,69,53,125,36,35,108,139,42,34,120,139,39,136,138,136,112,120,132,132,123,136,138,129,57,140,137,137,135,130,97,97,128,117,121,117,136,135,140,128,130,140,136,87,134,76,80,136,72,91,62,125,100,140,109,98,136,105,136,140,103,136,94,140,129,136,140,137,139,100,74,138,81,133,69,139,132,134,111,125,140,127,114,78,48,96,61,135,135,118,110,87,63,136,119,59,126,104,74,123,92,103,51,26,125,29,115,114,114,133,55,126,58,56,105,101,51,83,104,61,70,120,48,78,129,119,67,93,64,137,128,137,83,114,116,80,125,125,110,137,128,106,91,125,141,96,39,100,107,99,120,143,79,128,122,93,140,120,128,82,120,65,113,100,136,137,133,139,135,131,110,89,140,130,132,132,144,130,17,115,98,90,125,91,135,108,139,26,17,126,95,103,61,28,75,112,65,120,133,100,139,141,104,91,134,56,138,141,97,136,39,138,112,27,134,94,90,133,113,130,140,67,139,68,48,81,93,78,116,137,89,118,131,120,132,134,47,138,137,73,137,137,137,140,135,112,103,136,88,74,42,136,54,117,137,96,140,126,67,132,95,147,138,144,87,138,69,120,130,136,124,132,139,91,99,136,91,125,119,119,132,126,35,136,95,134,71,138,103,85,139,57,139,64,82,56,123,141,141,140,115,140,102,109,65,29,107,83,119,122,59,137,19,131,30,81,72,147,142,106,83,72,94,51,126,120,20,137,118,104,38,92,81,114,52,132,68,87,133,136,140,109,83,127,99,137,96,78,136,102,113,69,126,141,75,131,58,140,133,100,139,113,129,78,128,137,135,126,139,139,109,94,93,66,97,118,108,134,143,102,109,114,67,105,102,24,60,91,135,105,135,38,103,81,129,62,142,50,140,35,126,127,48,64,125,137,98,61,97,26,90,122,136,97,52,137,139,78,58,102,133,125,126,66,136,135,106,35,33,134,104,84,139,140,91,85,107,137,74,133,135,144,42,143,69,142,82,45,57,136,136,113,34,89,117,96,120,50,70,94,73,139,84,79,136,119,44,134,93,105,78,68,128,90,140,84,84,76,136,109,73,142,136,104,81,122,136,78,137,135,64,40,79,142,76,95,134,129,136,11,139,39,113,109,117,110,142,115,88,81,138,74,140,95,146,137,136,45,91,143,109,41,95,89,57,23,103,60,136,109,136,137,60,136,135,93,136,112,73,143,140,91,58,94,128,79,119,116,34,136,80,79,136,129,136,55,139,55,65,68],\"type\":\"histogram\"}],                        {\"bargap\":0.2,\"bargroupgap\":0.1,\"title\":{\"text\":\"Distribution of Text Lengths\"},\"xaxis\":{\"title\":{\"text\":\"Text Length\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bc34aa4d-0033-4044-b9f9-fee394c3f6b3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Analyzing the distribution of text lengths through an interactive plot\n",
        "\n",
        "train_text_lengths = df_train['text'].str.len()\n",
        "test_text_lengths = df_test['text'].str.len()\n",
        "\n",
        "train_hist = go.Histogram(x=train_text_lengths, nbinsx=50, opacity=0.5, name='Train')\n",
        "test_hist = go.Histogram(x=test_text_lengths, nbinsx=50, opacity=0.5, name='Test')\n",
        "\n",
        "layout = go.Layout(\n",
        "    title='Distribution of Text Lengths',\n",
        "    xaxis=dict(title='Text Length'),\n",
        "    yaxis=dict(title='Frequency'),\n",
        "    bargap=0.2,\n",
        "    bargroupgap=0.1\n",
        ")\n",
        "\n",
        "fig = go.Figure(data=[train_hist, test_hist], layout=layout)\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "ODUvmgDUF53K",
        "outputId": "5acd05d1-12e2-4990-9523-06a0657dd106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"9c46cd03-033e-4646-ac11-94e4fc79080d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9c46cd03-033e-4646-ac11-94e4fc79080d\")) {                    Plotly.newPlot(                        \"9c46cd03-033e-4646-ac11-94e4fc79080d\",                        [{\"name\":\"Train\",\"nbinsx\":50,\"opacity\":0.5,\"x\":[14,8,24,9,18,23,17,17,13,12,9,30,19,9,12,5,3,3,5,9,4,5,2,5,1,9,6,3,3,5,3,8,15,16,8,15,25,10,24,6,18,13,26,10,18,20,16,10,18,32,12,13,22,13,28,23,18,25,28,24,18,23,21,26,17,11,23,34,17,21,26,20,22,4,15,16,12,11,16,20,39,24,19,25,16,22,16,28,27,8,11,16,17,11,6,30,24,29,12,23,22,22,10,22,31,13,31,10,26,13,13,12,24,4,31,31,31,12,31,31,27,19,30,12,28,22,28,24,29,12,6,4,24,21,16,26,23,24,16,22,25,25,13,14,23,17,20,22,19,13,27,23,24,15,14,13,28,13,23,22,21,28,13,27,22,6,14,23,14,9,25,25,15,25,16,11,23,12,15,15,23,16,18,15,6,17,15,10,23,21,15,12,15,15,29,18,14,15,9,22,14,15,15,14,14,14,22,15,15,19,21,8,17,23,8,19,19,20,24,5,24,16,15,23,19,22,24,22,21,8,21,10,26,21,25,13,24,24,24,18,25,27,9,20,24,8,24,4,16,18,24,24,24,24,21,11,15,35,14,24,27,33,35,27,16,27,24,16,24,16,24,24,13,17,7,22,2,25,20,27,9,23,13,5,28,11,26,22,30,16,27,20,18,21,21,26,26,23,15,21,4,24,25,28,21,21,36,7,12,14,21,15,28,20,29,27,22,21,28,21,21,4,27,3,31,17,24,27,20,19,28,22,31,12,7,25,5,27,38,13,18,23,26,32,46,15,16,17,18,15,15,17,19,25,23,20,23,14,17,22,17,16,53,19,16,17,14,16,27,24,16,15,16,15,25,24,24,24,17,16,17,22,21,7,19,23,15,15,4,18,11,13,12,13,11,25,9,23,20,21,17,5,25,15,21,18,15,14,18,17,17,13,9,13,9,17,9,13,9,5,14,9,16,21,24,22,10,19,7,15,23,6,18,3,12,13,17,15,22,7,12,8,9,24,20,18,17,16,16,9,12,21,18,17,14,16,16,11,21,16,16,17,14,26,25,28,17,27,17,8,15,25,25,22,16,27,25,12,16,14,21,4,9,22,29,5,8,24,25,13,20,20,20,22,8,20,13,6,24,20,20,28,16,17,20,20,20,24,20,14,20,20,20,26,20,14,20,19,18,7,23,21,13,27,20,18,21,14,18,19,25,13,17,15,22,17,26,19,30,14,9,19,17,26,13,26,9,22,20,19,23,22,22,28,25,23,20,27,8,19,11,16,17,21,17,6,27,10,7,22,20,22,21,18,13,24,19,11,16,21,29,20,14,27,19,24,20,18,24,22,23,18,16,25,15,18,25,13,14,27,19,19,11,16,17,14,16,27,19,21,5,25,20,22,39,25,17,16,22,20,24,28,18,23,5,11,19,23,28,28,5,20,32,37,5,37,26,24,12,20,4,10,18,27,7,6,24,15,22,16,12,9,17,14,13,4,26,24,20,11,15,31,14,6,17,23,18,11,18,18,21,18,15,28,24,12,9,23,13,18,19,25,25,25,15,23,14,28,8,17,21,15,27,16,9,29,23,25,14,6,21,7,29,26,22,6,19,25,27,30,17,20,12,15,13,21,14,22,32,16,17,15,23,9,11,14,27,7,12,12,8,14,21,10,30,10,15,12,11,15,26,22,7,6,15,12,17,9,13,16,13,21,19,31,27,28,31,23,19,11,16,28,6,9,26,29,17,29,4,20,6,5,16,20,24,17,13,6,6,29,18,25,27,4,4,36,17,14,14,14,25,14,21,11,25,18,23,13,9,8,17,20,24,11,29,23,27,25,27,24,8,6,25,10,20,7,26,27,16,28,4,19,25,3,28,9,7,12,13,24,60,10,8,11,8,14,25,5,10,8,7,9,10,12,11,13,17,29,6,5,14,15,29,24,20,21,8,22,14,26,17,19,8,23,16,18,18,6,12,12,7,19,12,14,4,12,18,25,6,14,22,8,17,23,12,9,5,25,18,16,20,16,26,13,27,9,27,22,25,33,3,9,33,23,23,26,13,28,7,11,27,7,15,21,16,25,20,25,15,28,26,29,9,5,7,25,33,14,13,20,33,25,24,27,25,20,25,24,27,26,22,15,23,20,24,32,7,11,7,32,14,24,22,22,33,27,23,21,21,15,19,26,22,17,25,32,22,22,18,23,17,25,21,22,23,14,21,23,28,24,21,23,16,22,28,28,16,6,17,25,29,5,14,13,8,10,25,15,20,28,15,18,23,25,15,27,28,29,32,24,14,22,30,14,31,7,9,14,20,21,13,19,14,11,14,19,23,6,26,25,14,24,18,17,7,12,24,24,4,22,25,18,18,10,17,17,30,10,12,8,25,19,20,17,8,26,15,21,19,25,22,23,13,12,27,7,7,17,12,16,14,9,26,16,13,14,9,27,9,16,23,32,10,9,8,25,8,18,15,20,27,31,9,29,7,24,24,14,10,26,17,23,26,20,30,9,25,22,26,6,12,18,22,13,30,24,20,23,11,20,24,11,25,14,28,12,19,14,30,7,5,16,24,14,22,24,24,25,16,20,24,13,14,10,11,11,11,11,27,14,18,11,18,25,14,11,22,12,22,13,21,22,18,22,23,13,25,26,14,18,13,21,24,13,30,17,17,25,26,13,13,19,17,22,13,13,23,18,13,23,24,13,26,21,25,14,17,17,24,22,11,14,22,27,21,24,12,21,26,14,25,7,16,19,21,27,17,25,18,12,18,23,9,11,16,25,13,21,23,24,17,25,17,16,13,13,14,27,22,24,17,21,8,23,24,27,24,19,26,25,22,8,21,23,23,28,17,22,22,17,25,23,22,25,18,16,27,31,5,8,72,27,26,26,30,14,23,14,10,12,16,13,10,32,15,21,8,24,21,24,18,16,19,20,12,24,11,23,23,25,16,25,22,23,21,17,11,12,23,21,14,22,9,19,31,4,17,16,14,11,22,19,10,19,23,16,17,25,18,28,21,17,21,27,18,22,25,24,23,29,23,27,32,22,13,9,24,22,23,23,27,14,22,17,23,20,14,21,15,13,19,19,27,23,27,21,28,12,28,30,29,20,13,22,29,16,21,23,23,7,11,25,14,27,22,21,28,22,20,19,29,8,20,22,29,13,15,14,31,20,19,24,23,14,25,5,23,16,26,27,16,17,26,27,13,24,23,22,17,23,19,11,19,23,18,17,11,15,23,22,21,24,23,23,26,23,6,21,25,14,14,17,21,25,24,19,7,24,16,17,4,18,5,14,20,7,13,26,24,10,22,17,30,21,19,23,8,24,22,23,23,20,23,3,18,20,19,25,20,18,23,22,12,15,17,30,28,22,30,26,17,20,16,29,13,24,34,11,24,22,20,16,16,16,24,14,16,11,23,17,16,25,20,22,15,14,16,17,16,15,13,21,15,26,21,17,23,16,25,19,18,19,22,29,25,24,12,25,13,23,21,14,25,24,19,21,26,17,24,21,19,25,31,14,26,23,24,21,13,17,27,14,18,31,31,29,11,13,12,13,24,14,17,9,26,8,8,29,27,15,7,38,11,14,15,15,26,27,33,12,19,26,23,34,27,33,10,12,21,21,13,23,24,15,20,22,22,24,22,15,15,18,14,17,8,15,18,27,8,33,14,19,16,24,11,14,22,12,20,8,27,25,32,27,45,23,17,22,32,10,25,24,17,8,20,25,10,18,24,24,24,27,7,21,25,25,19,13,9,12,15,13,23,24,4,26,23,9,23,21,8,22,23,23,9,10,14,14,19,21,10,23,24,23,10,16,10,31,16,18,25,25,20,26,19,19,23,9,22,19,25,29,21,21,20,23,26,20,23,23,23,25,16,11,19,15,25,29,24,26,27,28,32,6,13,20,26,32,23,25,23,21,23,26,22,19,20,24,14,21,16,17,25,22,17,24,18,10,21,14,21,30,24,16,14,18,16,20,16,10,29,11,20,23,28,20,23,15,27,14,16,19,17,11,15,20,10,21,23,12,18,24,12,19,24,13,17,12,16,24,7,10,27,7,25,8,11,25,8,27,26,10,17,12,19,11,14,15,24,11,22,14,14,19,30,24,24,29,14,24,12,25,10,18,8,23,12,7,13,18,20,39,24,19,26,7,27,29,20,29,16,16,23,26,15,21,23,16,16,24,9,17,13,6,8,10,12,17,9,8,14,17,21,12,21,28,10,18,11,9,14,9,18,8,36,8,32,18,21,12,19,5,1,8,5,8,6,17,25,5,19,10,25,10,15,14,21,16,11,23,5,8,14,11,23,10,6,22,22,22,11,12,25,23,23,6,8,33,18,24,17,9,11,10,38,21,12,20,8,10,20,17,7,27,21,29,19,12,22,39,31,38,31,10,9,21,13,32,17,14,9,23,24,31,20,26,16,15,18,28,20,11,19,23,23,23,7,15,13,26,22,19,11,19,19,21,15,12,21,23,22,24,21,11,24,22,21,8,28,10,13,14,13,13,34,9,11,32,14,29,24,26,16,20,27,18,6,15,27,21,6,18,32,13,24,21,23,18,21,7,10,5,24,33,27,7,23,23,24,23,12,25,25,24,24,17,30,15,24,10,17,20,17,23,29,17,17,14,25,17,7,20,22,25,12,22,26,29,27,12,24,20,17,19,14,23,17,6,30,18,26,20,30,12,10,29,19,35,20,16,6,34,10,16,13,8,5,23,22,37,33,10,6,11,9,22,10,14,25,4,17,28,15,20,23,13,10,6,5,16,10,10,28,19,27,15,16,24,16,8,18,14,12,7,19,26,26,19,31,13,27,25,25,27,26,27,21,22,14,26,21,5,25,25,18,5,28,16,25,10,30,26,25,19,22,23,26,11,17,25,23,26,24,27,19,31,15,7,31,16,33,17,17,17,25,33,18,21,20,24,16,20,32,14,13,12,20,12,14,16,23,16,22,23,16,20,9,26,24,16,17,17,19,27,7,29,25,10,25,15,25,22,10,18,26,24,25,22,14,15,25,22,24,27,15,17,24,32,18,8,31,23,22,32,25,24,23,17,27,30,30,25,17,19,29,15,30,25,29,30,18,28,29,18,20,14,27,22,29,27,29,23,18,29,29,23,10,28,27,25,13,19,23,17,21,26,11,9,13,13,15,24,10,13,10,22,25,21,27,10,14,23,10,12,21,25,28,25,26,22,22,30,14,16,10,14,26,18,26,9,30,22,11,25,9,16,6,25,25,13,25,24,14,25,21,10,7,11,24,11,16,14,14,19,12,18,20,9,14,22,22,19,17,17,9,23,13,8,18,7,25,16,23,25,25,13,12,19,11,19,18,14,21,17,12,18,30,14,32,30,28,20,28,17,22,30,22,17,18,18,30,10,30,28,10,23,17,18,10,13,16,22,11,23,30,15,26,18,20,17,15,18,27,25,26,23,18,21,24,9,23,16,14,30,9,23,24,32,23,25,22,27,30,7,22,22,17,26,29,23,15,22,12,20,18,24,24,24,7,10,17,10,29,19,23,14,15,22,19,10,25,17,25,22,10,21,25,24,12,26,19,34,22,13,25,22,26,16,18,17,14,22,25,26,13,19,24,10,24,18,25,22,14,23,18,26,20,14,25,22,26,7,16,27,22,24,2,15,23,27,10,24,15,19,28,16,20,14,30,22,22,26,18,18,21,31,26,26,14,20,16,17,15,20,22,22,28,29,27,21,23,22,18,26,28,16,18,16,22,7,25,26,8,18,5,22,14,16,21,22,25,12,18,18,21,15,28,15,20,28,8,23,24,25,24,26,19,14,12,20,3,8,28,28,25,15,6,28,24,28,14,18,20,25,21,4,8,22,16,25,20,20,25,20,16,19,24,8,22,16,24,27,25,29,20,20,27,20,44,25,16,20,20,21,20,11,20,21,13,27,13,16,9,10,22,23,6,12,19,19,20,14,19,9,20,10,23,24,7,11,26,20,5,13,12,10,21,21,9,13,19,21,11,13,23,21,12,16,26,20,11,16,14,8,29,12,21,20,13,12,13,25,18,25,21,16,28,18,12,21,25,22,18,15,14,14,14,15,16,25,13,17,14,15,15,14,12,15,14,21,14,17,16,28,15,17,18,15,15,21,15,18,18,14,22,22,24,18,31,23,19,11,19,24,19,24,19,7,19,26,13,19,30,17,9,12,19,11,17,10,6,5,17,31,19,17,29,22,21,23,26,25,23,23,12,22,24,23,21,23,15,22,23,26,29,26,33,23,16,21,23,23,25,20,21,23,24,23,21,24,14,11,11,9,24,24,10,26,19,5,10,9,29,22,25,24,18,21,12,17,8,10,7,30,23,14,20,26,13,30,30,13,15,26,17,17,24,26,24,22,21,29,28,22,21,23,12,17,28,19,24,24,24,24,14,16,22,27,16,15,16,24,13,20,27,24,22,17,22,21,22,16,28,8,8,22,27,12,14,19,11,28,10,25,21,23,10,23,17,26,15,10,10,31,23,23,27,17,15,22,11,12,19,13,26,26,19,29,27,24,12,26,19,19,5,18,12,16,14,11,10,20,12,37,8,11,11,11,24,14,11,26,24,22,25,27,19,10,30,22,36,9,12,26,11,20,9,17,32,27,19,17,33,17,20,16,8,15,17,16,15,28,13,31,13,13,23,21,31,27,12,16,23,5,25,22,24,6,21,21,28,9,20,18,26,8,21,11,18,7,18,15,15,19,10,19,23,22,11,24,9,21,26,6,27,28,4,18,23,12,14,32,21,15,18,20,23,26,15,9,13,17,28,13,21,20,21,17,8,16,29,22,24,19,31,10,23,27,14,23,26,30,16,26,16,23,19,22,18,17,24,23,19,24,13,16,24,23,19,24,21,23,23,36,16,9,21,15,20,23,22,20,24,16,3,19,24,24,8,25,4,20,16,23,21,18,5,11,28,10,24,25,24,11,2,6,15,8,15,13,11,28,10,28,26,19,15,5,30,7,26,17,25,17,29,9,23,13,21,24,22,10,33,13,33,12,21,13,14,16,13,20,28,21,20,30,28,34,22,21,12,25,18,22,25,11,26,24,22,23,15,10,21,22,13,12,22,2,21,19,20,19,16,17,22,20,28,21,22,25,11,18,19,23,29,22,24,18,10,15,22,18,29,23,24,21,23,23,23,8,29,24,23,22,22,21,18,20,11,24,21,13,22,16,17,16,18,24,17,15,18,27,27,23,21,22,27,22,27,14,20,13,18,19,32,25,16,28,14,27,27,13,24,28,24,14,17,19,26,24,20,23,24,27,8,27,26,30,22,27,26,24,20,22,25,20,25,12,20,20,27,24,20,27,24,24,11,18,27,18,20,27,6,18,15,9,24,24,18,23,12,27,23,19,13,18,27,20,20,20,18,21,22,18,21,19,14,13,19,16,22,8,22,14,23,28,25,32,21,41,23,28,14,10,16,23,15,18,25,7,10,13,18,16,17,33,20,17,19,13,23,27,21,29,13,13,19,17,26,5,23,21,10,19,29,15,20,20,24,24,9,15,21,19,19,24,21,17,28,19,27,23,13,16,18,19,21,13,12,28,13,5,22,12,21,17,23,24,14,27,12,24,23,14,11,24,11,15,19,23,24,20,19,28,22,13,24,27,21,25,24,20,23,19,17,16,25,20,14,25,24,10,25,27,22,16,16,11,30,15,25,11,28,21,29,12,21,30,13,21,11,17,7,24,30,22,17,9,30,6,16,26,12,21,15,23,30,15,8,30,15,6,9,13,23,17,27,24,27,8,43,12,33,31,12,14,23,16,28,25,24,12,14,6,10,24,16,26,30,5,27,25,21,11,16,23,31,29,20,16,24,13,22,15,19,15,17,37,15,18,21,20,17,17,23,16,20,19,11,20,15,23,13,20,20,32,3,22,15,27,23,20,26,11,22,23,21,18,7,10,18,17,20,29,20,21,24,24,25,22,18,14,10,17,17,22,17,22,21,21,21,18,11,22,25,21,20,25,27,22,11,13,20,24,26,8,17,13,28,24,24,13,20,22,12,30,13,22,19,18,20,11,20,16,27,16,11,24,21,13,14,12,13,21,25,24,17,16,23,14,22,13,15,12,20,20,15,13,10,23,11,23,15,23,14,14,18,23,17,23,23,12,12,23,23,23,14,12,2,28,23,12,11,23,23,12,17,27,24,15,28,22,23,26,26,18,12,20,23,10,7,21,20,24,8,9,20,22,11,13,19,20,19,12,22,24,10,19,24,11,23,13,18,18,21,16,24,21,25,26,16,24,13,5,24,31,10,2,14,14,1,18,27,13,4,11,19,14,10,14,4,13,33,6,13,16,4,13,4,13,31,22,15,22,32,20,5,20,8,14,26,15,30,11,18,24,22,11,31,23,23,11,6,29,27,25,22,7,17,19,16,7,9,27,23,21,16,29,11,22,19,8,25,27,21,25,4,20,18,17,25,11,27,7,14,8,14,8,9,3,16,8,27,21,23,17,10,7,8,15,27,8,9,24,23,26,17,16,9,18,17,22,4,13,20,15,26,29,23,11,26,24,20,24,16,22,9,12,35,16,26,11,31,33,31,26,26,21,14,11,8,11,22,8,9,26,16,23,18,18,25,13,24,23,25,15,29,23,28,22,16,14,26,13,25,17,13,16,18,19,17,19,15,30,21,21,25,20,16,23,23,16,7,18,26,7,17,12,14,10,17,14,23,22,23,17,20,6,19,31,24,8,32,23,22,14,23,10,20,23,23,23,23,19,22,23,12,12,19,28,8,10,9,4,26,25,12,24,28,24,22,3,15,7,23,27,12,5,28,24,26,27,21,5,6,30,21,24,27,29,24,18,17,24,24,13,18,24,29,26,18,24,5,25,24,12,31,20,27,26,24,19,19,24,17,22,24,24,24,15,26,24,19,17,27,25,22,12,14,25,22,19,21,8,14,21,19,12,26,30,12,15,26,18,16,12,20,21,8,22,20,23,18,10,25,9,17,22,19,9,14,20,23,28,18,27,22,26,34,28,12,21,20,8,30,26,22,26,28,18,21,19,29,12,18,13,24,24,17,26,21,17,23,27,14,17,3,20,26,27,17,18,23,22,8,12,22,19,7,20,23,15,12,31,33,26,24,12,21,14,22,36,30,20,14,23,18,17,24,17,14,21,14,17,28,21,18,24,21,24,17,12,21,15,14,20,18,19,20,27,19,21,9,20,15,29,18,29,28,28,12,19,17,29,18,25,27,22,31,6,25,9,9,22,6,7,19,14,25,34,22,11,12,6,25,29,18,21,8,22,28,20,17,16,16,18,12,8,18,13,15,25,30,15,28,24,6,19,25,14,6,24,17,25,18,27,18,19,21,18,13,23,9,29,20,29,28,18,12,29,29,20,15,33,35,24,27,7,24,16,19,17,11,22,18,16,11,14,29,27,30,22,30,13,12,20,27,21,25,13,18,24,11,10,4,22,23,13,26,28,20,8,19,16,16,20,11,20,30,25,19,21,19,15,11,15,18,19,22,25,21,25,17,19,26,23,11,11,15,13,15,20,24,13,17,24,11,24,13,24,13,23,10,28,16,10,11,15,12,20,18,11,24,13,20,24,13,13,17,31,26,27,11,13,22,26,14,22,6,27,24,35,15,17,21,29,28,22,26,22,7,22,18,21,22,8,26,24,27,16,25,22,9,22,26,18,26,20,24,12,28,24,26,23,20,30,12,16,17,28,29,16,32,24,26,18,25,22,20,26,23,24,28,18,15,7,12,27,26,25,25,15,25,25,27,17,21,14,24,21,15,17,22,26,17,23,13,16,20,21,23,14,18,7,21,14,17,6,25,24,15,14,24,26,15,20,20,15,16,15,14,10,21,11,15,15,10,13,21,15,15,11,19,11,17,13,14,10,14,17,13,17,19,21,17,12,15,14,15,10,22,24,24,24,24,16,24,24,10,24,24,13,25,24,24,24,26,24,24,13,16,17,24,28,24,24,10,14,10,23,24,22,22,18,23,18,17,6,16,24,13,10,34,13,16,19,26,13,22,13,16,27,24,22,24,13,22,12,17,20,8,21,21,24,24,25,21,21,14,14,12,24,24,25,15,22,17,28,35,26,12,23,21,26,8,24,24,27,27,24,35,22,22,35,18,24,24,30,22,12,5,24,19,9,19,6,12,18,20,16,13,17,12,4,5,15,22,16,12,7,7,11,21,20,16,22,23,28,28,19,9,20,3,22,4,25,15,22,29,12,12,18,23,13,24,15,24,13,10,20,18,10,14,26,27,11,23,22,4,14,19,23,21,21,21,26,22,23,14,21,13,22,9,17,21,26,22,28,28,25,9,28,17,22,17,20,22,14,27,18,21,23,22,21,15,11,27,27,15,29,21,16,8,12,23,22,19,17,18,15,18,19,30,18,9,17,28,23,25,26,20,17,10,19,27,23,14,15,17,22,13,11,10,15,21,31,18,15,27,18,37,15,13,23,12,21,26,25,27,23,23,16,27,18,29,27,23,23,12,27,25,19,23,26,26,31,24,8,23,21,22,31,28,25,32,12,27,31,17,27,17,15,21,19,13,11,7,9,6,35,20,26,11,25,17,26,10,26,27,23,27,13,25,12,18,20,23,29,14,23,21,22,17,27,12,11,26,31,14,10,29,15,24,10,19,17,15,30,24,25,24,15,14,26,6,12,15,29,8,24,17,8,13,27,13,4,25,10,33,29,23,9,13,20,22,13,23,21,8,18,25,30,19,16,25,14,18,18,5,17,10,16,19,17,25,18,11,10,17,26,19,12,4,22,15,20,18,21,30,30,14,12,30,34,30,30,30,28,26,30,25,33,16,30,32,16,30,30,16,30,30,40,30,31,30,16,33,26,30,16,30,21,23,23,10,31,28,22,7,25,14,20,12,25,22,24,19,23,13,31,14,24,25,29,23,26,21,9,19,21,19,20,23,26,19,7,23,25,14,35,23,24,25,32,25,10,27,22,21,17,23,8,18,15,23,19,8,26,10,15,16,14,24,7,14,10,19,26,19,13,14,19,24,21,26,22,34,16,19,22,2,6,16,20,6,20,24,33,13,14,13,27,22,18,26,11,23,30,19,19,25,20,12,24,14,19,11,16,25,14,25,26,3,8,25,26,7,18,13,70,25,13,22,26,10,28,19,15,25,20,10,16,26,29,16,9,9,19,8,52,25,12,8,29,15,22,18,25,30,32,12,21,15,24,7,18,25,18,6,16,27,1,16,13,19,15,25,18,23,24,32,22,19,19,10,15,23,24,19,20,22,17,14,22,28,27,23,17,22,23,17,17,22,15,22,32,22,21,22,25,13,16,18,12,19,11,21,20,22,20,13,12,18,11,21,14,8,31,9,15,9,27,21,22,19,5,10,9,11,7,6,8,16,17,7,21,11,15,18,25,15,14,17,21,7,13,31,23,23,16,21,22,29,16,16,24,19,18,26,24,15,9,19,17,25,20,23,22,19,13,24,20,19,17,32,24,25,22,15,12,28,13,30,13,12,24,26,23,26,13,26,19,21,13,20,24,14,24,12,13,24,34,26,18,22,1,26,15,15,16,24,23,23,24,9,21,12,19,20,25,23,12,32,17,9,25,14,8,10,21,15,17,23,15,18,19,12,22,24,14,13,26,25,25,24,12,30,25,11,22,11,16,17,16,11,19,6,22,9,20,13,21,28,27,14,20,24,16,18,27,16,23,12,15,1,16,12,6,24,21,27,20,15,18,15,25,25,25,28,7,27,15,6,15,10,12,12,17,15,21,31,10,7,31,20,17,15,20,32,18,24,29,12,7,12,16,19,10,14,12,24,27,27,28,15,17,20,14,15,25,23,16,24,15,23,16,17,13,13,13,13,13,16,23,15,25,22,24,23,13,17,23,19,25,20,27,16,7,14,13,13,16,15,17,15,23,13,16,11,17,23,24,23,15,19,24,22,23,25,27,23,23,24,23,23,23,23,24,26,23,23,14,23,26,23,23,23,23,14,24,23,16,24,26,23,23,26,23,23,21,5,19,19,25,16,31,21,20,13,18,15,6,17,15,16,13,25,17,13,16,16,29,16,24,11,17,20,16,13,18,16,12,21,18,15,25,19,5,7,15,25,28,12,14,29,10,9,32,23,19,25,13,23,16,13,26,23,19,20,32,32,26,5,23,13,26,28,24,12,23,29,22,9,6,28,14,18,11,14,14,12,5,21,24,14,16,10,18,28,18,20,16,10,20,26,9,13,23,17,13,6,29,22,10,15,13,17,24,26,23,15,22,16,19,33,16,24,23,12,16,20,20,16,23,20,20,26,24,22,11,20,15,19,21,21,17,24,33,21,30,23,13,26,22,20,9,15,16,13,18,12,25,13,20,13,12,9,8,18,21,21,13,13,16,23,12,22,21,19,21,9,9,11,13,23,9,11,9,20,29,20,20,23,12,23,17,17,20,12,23,20,12,11,15,25,14,20,20,20,24,18,29,28,14,14,21,23,20,30,16,14,20,27,20,23,11,16,13,19,25,19,22,25,16,27,16,15,23,25,17,20,25,26,14,26,25,27,20,22,20,15,20,26,29,6,26,8,12,30,23,6,30,25,24,18,10,18,15,13,16,15,22,17,16,16,21,25,16,16,17,17,17,26,17,17,16,9,16,16,17,15,15,25,18,16,16,16,18,17,16,17,16,18,24,12,20,16,26,15,21,9,14,15,21,23,8,22,23,11,27,8,15,22,18,15,14,24,29,20,23,29,9,20,23,10,25,15,29,27,12,13,18,18,23,29,18,18,11,12,18,18,23,17,16,15,18,24,14,15,18,18,30,16,14,9,36,23,22,21,22,11,9,24,8,11,16,10,21,23,25,22,26,17,13,10,16,23,14,10,15,25,36,24,21,22,9,27,25,25,25,25,26,22,12,23,26,26,14,25,25,26,27,26,26,28,25,22,25,24,26,25,25,23,24,26,17,23,11,15,23,28,28,11,7,22,20,17,14,17,21,26,8,18,22,22,20,23,22,15,16,16,22,21,28,30,22,16,25,25,21,18,11,22,22,11,21,24,18,10,20,15,19,12,28,19,16,16,17,17,27,32,25,17,25,6,10,16,27,13,14,29,25,30,23,13,19,21,16,25,28,23,28,25,21,21,30,23,19,29,20,23,26,16,19,24,18,24,22,27,7,19,20,23,19,20,26,12,19,28,18,7,10,27,11,14,15,6,26,19,25,7,18,13,15,14,19,17,21,10,25,17,10,7,25,9,22,11,16,21,17,31,16,26,10,12,15,16,16,29,16,12,16,16,16,16,16,23,8,16,16,16,16,13,22,16,16,16,16,16,16,16,16,10,16,16,16,19,16,11,11,15,16,11,17,28,13,14,27,27,21,23,9,15,15,32,20,16,23,15,25,25,29,22,24,28,13,13,9,9,26,13,16,9,8,12,24,15,16,11,28,6,6,3,6,20,8,8,20,15,23,11,4,3,11,28,22,27,17,14,14,7,18,21,4,28,5,9,6,8,12,33,7,8,6,7,33,7,4,6,29,38,18,14,12,9,5,6,14,5,14,13,14,18,29,10,36,22,12,12,27,16,28,12,31,18,3,8,7,26,16,25,13,27,26,20,23,20,25,24,14,17,20,25,26,23,24,9,26,18,16,16,10,26,25,15,15,24,31,27,17,17,11,10,13,17,11,30,11,14,26,16,23,11,28,20,11,19,11,11,12,16,9,14,22,24,20,15,12,10,28,11,14,31,8,17,21,13,20,27,27,18,25,17,25,25,17,11,26,15,18,15,8,20,25,20,15,30,21,21,21,16,11,35,26,33,17,24,24,20,25,15,7,22,25,9,20,21,19,27,5,7,16,26,9,30,29,19,18,16,36,9,31,23,28,15,15,15,17,32,42,21,14,33,14,14,13,9,10,10,27,21,27,8,14,20,14,24,15,29,18,24,5,17,14,3,6,21,25,12,20,26,5,22,28,6,17,17,22,20,27,14,16,7,16,23,15,12,10,4,9,31,20,21,12,21,6,17,7,25,20,9,5,31,17,18,20,9,9,24,20,6,8,26,15,3,16,26,24,11,17,12,30,27,27,19,13,28,17,20,22,19,11,22,24,17,12,26,19,13,32,23,28,24,20,23,29,27,25,3,25,22,14,8,22,17,28,13,25,16,23,22,15,18,17,19,14,23,6,8,21,25,15,18,4,23,10,22,16,27,18,26,15,27,20,17,23,16,25,24,19,17,15,19,14,20,15,9,18,14,8,10,16,22,13,16,16,16,27,10,17,22,28,17,16,14,10,23,13,21,14,22,20,21,19,19,17,20,17,15,18,26,21,24,20,12,20,20,26,22,24,9,24,20,21,23,24,12,22,16,20,21,23,26,20,21,21,20,17,21,18,24,27,5,20,21,23,23,20,20,23,19,25,16,16,16,21,20,18,17,20,16,24,20,27,20,21,14,16,20,14,12,11,22,23,22,15,15,21,26,9,13,26,14,28,24,17,28,22,9,14,22,24,25,25,22,13,28,24,24,18,27,26,18,9,14,19,15,12,22,22,27,8,19,25,12,12,25,28,22,14,26,10,22,15,23,12,25,24,22,15,25,18,20,19,15,22,13,26,17,12,23,18,17,23,27,13,26,17,32,28,19,25,14,12,26,10,15,31,22,24,34,22,10,12,11,28,30,13,23,20,19,22,19,15,16,28,14,20,6,14,19,16,26,6,15,28,16,19,33,12,22,21,5,29,23,10,22,13,8,17,22,21,19,29,29,27,13,15,11,31,30,28,20,13,11,15,15,24,12,28,15,16,27,26,12,33,35,27,25,25,33,14,10,23,16,8,14,21,17,26,10,26,8,12,4,26,29,20,11,20,25,15,12,22,16,26,25,19,24,22,30,8,16,9,28,13,19,28,8,15,15,22,28,19,10,23,6,16,9,11,22,17,19,15,22,18,22,8,28,24,28,30,20,28,12,16,28,15,13,15,5,28,15,22,15,24,17,15,24,22,5,9,18,22,26,14,14,24,20,21,14,14,21,9,26,24,21,14,22,23,15,30,14,19,18,26,16,21,12,14,8,7,15,4,11,18,9,21,6,28,12,16,7,16,11,11,23,23,9,25,27,18,6,18,8,9,12,3,16,10,29,34,27,26,12,4,11,19,17,16,10,23,20,17,23,24,21,13,12,24,23,18,31,25,17,29,14,20,29,14,17,19,10,22,24,18,15,22,12,6,23,17,6,14,16,9,17,15,27,25,9,20,25,15,11,29,10,13,13,26,16,17,17,30,21,24,5,14,21,9,12,11,8,20,21,19,18,16,16,15,21,24,27,21,27,18,14,22,27,16,23,15,27,22,34,28,27,27,8,27,12,27,17,27,25,29,27,27,27,28,12,7,26,8,17,15,22,31,22,11,23,11,17,23,8,27,25,25,11,18,28,11,4,25,22,17,10,22,15,26,22,22,11,11,22,19,20,26,26,23,11,10,26,26,20,14,3,10,25,24,19,23,14,13,28,12,21,29,18,29,31,17,26,20,23,23,19,14,5,16,13,16,24,31,6,6,21,15,22,6,28,7,5,19,12,28,23,26,23,26,16,29,16,27,11,18,16,14,17,16,18,15,22,18,22,21,26,3,13,14,19,17,30,9,16,18,33,12,9,14,26,18,30,19,22,15,12,23,30,12,26,19,12,5,19,28,27,14,7,17,16,26,12,21,17,19,26,6,27,14,23,12,10,24,18,6,25,17,31,19,27,21,15,6,27,4,5,16,27,22,26,32,12,12,22,14,6,10,30,11,29,11,30,22,20,17,16,24,10,7,25,20,12,17,34,10,14,17,11,7,25,9,26,24,17,23,26,19,24,24,18,19,20,19,19,25,19,21,19,22,10,16,11,22,23,19,19,6,19,11,24,19,14,13,9,11,16,24,11,15,9,10,21,19,10,26,14,25,6,13,21,23,25,24,15,24,14,26,14,20,10,28,19,10,15,15,11,11,19,20,20,25,17,25,26,15,12,13,19,23,15,14,24,21,10,11,28,21,21,20,18,26,22,21,26,19,26,14,26,13,25,26,15,11,29,16,20,14,13,22,23,17,31,11,22,20,19,23,22,23,23,19,22,21,25,21,24,24,14,22,15,25,35,21,28,5,20,9,15,12,19,24,20,27,20,18,8,22,14,14,24,13,21,11,13,26,22,23,11,30,7,16,9,23,13,18,12,24,33,25,28,20,20,6,27,3,23,21,19,16,23,20,14,16,11,11,9,37,12,23,12,7,22,22,28,10,22,24,31,9,3,10,22,28,14,11,23,23,20,21,34,21,26,16,23,18,24,21,24,12,6,22,17,26,18,23,21,30,7,24,26,25,18,23,8,24,24,22,30,25,15,24,15,18,21,27,30,11,8,22,14,31,13,17,25,26,19,27,12,8,21,18,22,19,19,21,34,21,16,16,23,11,34,3,30,21,22,21,10,22,10,30,11,24,16,16,23,26,25,24,29,11,20,15,25,16,24,23,11,19,21,26,17,8,14,24,18,24,13,15,22,14,28,18,26,26,12,15,25,26,28,14,27,23,7,17,26,19,13,16,25,18,17,22,19,14,16,24,17,25,20,15,22,27,12,24,19,17,25,14,30,17,15,15,8,12,11,17,17,13,23,10,16,17,28,20,20,13,13,13,20,11,27,17,24,27,12,11,16,19,17,24,16,24,26,17,24,16,23,11,14,22,26,21,15,9,26,25,20,19,12,23,29,15,17,10,12,24,24,12,17,14,21,20,18,21,8,23,27,26,19,30,29,14,20,28,18,18,24,16,22,22,31,15,22,26,21,9,3,27,32,14,14,19,16,24,28,20,11,16,22,17,18,27,10,26,18,24,15,6,4,24,15,19,16,9,19,18,26,18,24,22,25,21,8,34,8,18,18,9,25,14,32,18,24,8,29,13,19,30,12,26,11,16,7,23,17,23,16,23,25,23,23,30,25,13,23,23,25,23,23,10,24,17,23,25,23,25,23,23,14,15,25,10,23,17,23,10,23,23,23,23,12,23,23,23,16,21,23,13,16,10,14,20,18,19,8,19,6,10,8,7,5,5,25,12,17,3,24,21,18,16,10,14,12,9,9,26,9,21,20,18,16,21,18,11,18,3,21,2,29,19,22,12,20,19,28,32,14,22,14,17,15,23,27,27,22,21,13,24,15,21,16],\"type\":\"histogram\"},{\"name\":\"Test\",\"nbinsx\":50,\"opacity\":0.5,\"x\":[6,12,22,7,8,8,16,6,5,3,7,7,7,4,2,19,10,15,18,19,10,13,33,24,6,30,14,30,13,20,30,6,19,16,16,29,19,29,24,26,25,25,13,20,21,15,29,31,31,31,16,30,24,31,4,13,16,15,20,4,21,33,11,27,19,14,26,14,15,25,12,25,22,22,22,12,13,15,21,27,19,17,16,12,15,24,27,20,24,24,27,30,12,14,16,21,15,26,20,12,8,9,14,16,21,16,24,11,21,24,24,14,22,13,24,24,22,24,24,18,24,24,24,24,15,24,28,35,28,4,24,14,21,20,20,20,14,25,18,28,8,28,7,9,6,23,13,25,13,28,14,25,17,21,15,18,16,16,15,17,17,17,17,28,17,19,14,13,14,16,22,23,23,26,20,12,15,24,13,4,13,20,25,23,19,24,16,10,15,19,9,24,17,14,6,6,12,17,11,13,18,7,16,24,11,27,13,15,17,21,23,24,30,14,22,23,23,20,20,14,20,20,24,22,18,20,9,20,23,25,9,19,32,21,19,23,18,13,18,11,18,21,21,16,20,9,12,11,12,24,8,20,24,27,18,22,15,19,19,15,21,23,19,23,19,19,13,13,22,18,14,20,37,18,10,20,11,24,17,37,10,24,11,37,18,5,5,32,33,16,16,11,4,21,20,5,14,6,11,10,20,5,11,27,13,27,3,31,27,25,17,11,23,17,25,27,23,24,17,22,13,20,22,10,18,21,25,28,30,7,12,11,17,7,18,6,11,7,20,6,8,28,30,13,31,6,19,25,30,11,22,18,12,11,16,24,13,11,6,27,21,17,27,17,17,27,27,5,6,19,16,31,11,5,22,9,29,25,15,12,22,21,18,15,9,10,13,14,11,14,31,23,22,25,27,22,23,20,6,9,8,16,17,20,13,26,14,20,15,32,28,23,30,25,20,18,12,26,9,18,24,24,20,14,19,23,22,22,15,21,21,25,22,10,19,22,25,23,30,21,23,14,22,24,17,30,19,23,33,7,24,22,28,13,6,5,12,21,24,19,26,16,27,10,32,20,20,25,18,18,27,23,34,31,8,27,30,19,15,17,15,13,17,27,21,37,23,8,22,27,27,28,27,26,17,31,11,12,7,24,17,12,16,14,8,18,18,17,22,11,13,17,14,15,20,19,23,13,20,23,21,16,13,17,22,24,22,23,13,23,24,16,11,23,29,9,22,24,16,23,21,26,21,32,13,26,24,26,32,31,21,13,19,25,15,26,22,9,27,11,14,25,27,22,24,14,18,28,22,29,14,17,28,21,20,20,32,25,11,23,23,26,29,6,18,28,5,14,18,16,19,17,27,14,13,16,28,30,28,25,21,14,12,20,28,22,18,23,25,11,13,16,23,19,23,25,19,17,9,15,10,28,22,18,22,24,28,24,15,22,27,23,7,22,4,34,18,30,22,16,16,9,16,33,4,32,2,19,18,22,15,7,16,21,18,22,23,19,20,24,23,11,27,13,23,9,28,23,16,21,24,30,18,11,24,23,11,23,29,15,22,16,25,19,25,11,13,17,21,19,5,13,19,17,35,16,14,8,9,15,27,18,19,28,31,19,24,26,15,12,10,8,27,15,18,7,17,17,24,20,18,20,11,22,20,23,14,19,23,15,9,20,27,25,14,6,18,24,25,26,16,24,16,20,22,9,12,16,2,11,26,14,25,21,22,25,27,33,24,5,18,23,27,22,17,27,11,21,16,15,3,14,22,12,10,20,16,24,27,12,1,8,14,20,15,26,26,13,15,19,20,20,30,17,15,31,14,25,24,9,10,24,16,15,15,25,22,26,27,23,11,12,6,14,17,12,30,25,12,9,31,25,25,21,29,19,26,24,6,13,4,10,25,17,27,6,13,4,22,28,13,22,33,18,11,27,19,21,17,11,17,11,8,24,11,15,24,9,4,27,12,22,13,18,21,11,17,26,19,24,18,17,24,24,20,13,12,11,6,8,17,12,31,26,35,20,22,15,18,13,20,28,26,28,8,24,4,9,17,24,22,22,8,16,22,19,29,23,15,46,26,19,11,25,13,18,31,25,10,26,25,15,8,7,11,19,14,23,5,21,5,25,15,29,29,22,13,26,14,26,15,14,15,24,23,13,17,31,24,16,22,27,24,20,33,25,25,17,25,9,15,17,18,26,29,29,24,29,13,30,28,17,29,29,9,29,29,30,21,30,20,31,24,18,13,21,14,13,19,19,24,26,18,28,25,11,14,19,22,18,17,23,9,25,22,25,7,21,24,18,4,26,18,14,8,26,7,11,5,25,12,26,15,20,8,13,30,12,23,22,17,15,20,10,28,19,18,30,30,12,26,17,30,31,15,25,30,16,21,23,19,15,24,16,24,29,18,9,28,24,28,15,27,27,21,13,25,23,22,23,17,23,25,11,10,25,16,21,22,18,11,17,24,23,20,19,28,29,27,16,13,8,3,24,12,17,22,9,12,22,23,25,11,25,18,26,21,23,29,10,25,26,12,11,12,18,27,17,18,29,26,20,16,34,26,28,18,20,13,23,26,26,28,12,27,10,6,23,24,27,20,19,16,20,21,20,24,14,19,20,20,21,18,22,8,18,25,12,21,17,24,24,23,22,26,24,18,15,18,15,10,14,15,15,15,17,14,17,17,20,14,15,18,23,6,8,8,9,17,19,20,19,26,29,27,19,26,22,23,10,11,13,28,20,20,21,21,21,15,11,11,26,26,25,25,23,22,20,31,29,11,20,7,18,25,20,7,11,22,15,25,21,18,24,24,24,22,22,27,13,23,24,1,17,24,27,13,14,10,17,23,6,8,21,6,17,24,12,22,10,6,31,10,22,8,8,4,18,9,15,18,4,27,11,13,11,6,21,13,23,16,23,35,12,14,11,27,28,23,14,7,10,24,21,15,15,17,12,21,21,14,22,22,21,26,7,11,16,12,19,12,20,23,19,16,16,24,15,15,9,18,24,14,7,16,15,27,22,24,16,15,9,6,22,14,33,17,5,16,15,15,17,20,22,23,31,27,16,30,17,30,5,15,25,34,19,13,9,26,17,23,19,6,23,8,24,24,25,21,29,18,21,22,28,9,20,13,10,24,11,15,28,23,26,15,14,22,22,25,15,19,21,23,22,17,29,22,15,20,11,24,25,14,15,27,27,24,25,21,29,15,10,18,13,27,20,18,18,17,25,24,23,20,19,18,11,18,26,38,24,22,13,23,5,17,14,28,14,22,25,12,16,28,20,8,15,18,22,10,21,18,15,12,15,30,14,15,18,22,26,19,22,17,13,24,11,6,28,7,5,29,17,9,9,19,9,15,18,22,31,14,25,12,13,23,26,24,29,8,25,25,25,12,15,37,20,20,28,24,22,18,9,25,23,21,19,10,25,25,25,24,14,17,23,22,20,20,10,20,23,21,24,16,20,15,23,14,8,26,35,28,24,16,17,10,19,23,23,25,23,7,21,12,16,23,28,15,15,20,22,11,5,14,12,6,28,23,28,2,19,29,3,29,8,25,19,27,24,17,7,22,27,10,10,16,3,11,25,20,18,18,27,11,27,11,13,16,27,28,27,16,24,26,19,15,14,26,25,15,10,18,29,22,21,14,14,18,20,21,27,22,13,23,18,28,21,28,23,20,16,38,22,21,9,27,24,33,27,23,10,6,11,13,14,19,21,30,18,30,23,24,12,27,24,4,21,9,15,20,14,24,12,31,30,15,24,25,24,18,24,25,22,21,25,24,26,20,20,24,15,10,19,8,9,21,18,13,27,22,27,27,27,10,21,18,21,6,33,22,21,26,24,12,16,21,19,24,19,26,15,14,10,15,25,15,25,24,18,15,17,22,36,11,21,19,23,29,31,18,25,28,25,4,30,31,14,15,25,7,13,8,15,11,15,20,29,20,14,23,25,14,13,11,13,8,19,24,42,25,28,25,30,25,23,25,38,22,19,26,24,15,15,18,20,14,21,11,11,18,6,15,14,24,22,24,9,13,24,11,24,22,24,18,24,23,25,11,19,28,26,29,17,12,21,19,27,17,13,17,27,24,30,13,13,19,18,26,23,29,25,28,14,30,26,24,30,17,16,24,17,17,20,16,16,1,16,16,20,14,15,17,15,23,13,14,21,10,29,15,32,15,19,15,24,15,21,21,24,10,16,24,24,24,24,21,10,20,11,15,28,24,25,24,24,15,25,17,24,14,16,16,10,14,16,22,21,24,18,21,26,23,7,25,10,24,14,24,24,16,27,23,12,24,24,12,24,23,24,21,15,29,22,19,13,8,7,14,5,22,19,25,17,33,8,22,25,10,14,22,16,23,22,25,30,21,12,20,24,12,24,17,14,25,13,36,26,16,24,14,18,25,17,15,15,16,22,21,12,18,22,24,15,26,20,33,30,8,17,22,22,25,24,25,33,25,14,24,24,19,18,12,6,21,14,17,28,11,23,15,24,15,26,28,16,14,32,13,17,23,7,11,22,14,9,15,3,15,24,20,30,21,11,14,5,24,14,19,24,8,6,18,14,15,19,4,4,19,24,4,18,13,9,30,30,30,30,30,30,30,30,30,14,19,26,11,26,30,20,28,25,13,28,21,13,9,28,25,20,25,15,24,32,21,25,28,10,21,12,19,35,19,28,18,23,11,28,20,27,21,16,9,16,8,22,19,23,12,28,18,26,15,20,26,20,25,19,26,21,36,26,16,30,20,26,26,12,24,23,19,26,25,24,15,17,8,21,19,29,13,8,24,12,24,11,29,3,15,15,27,19,18,17,20,18,17,22,17,4,9,23,23,23,18,16,14,9,15,14,17,31,19,6,29,4,7,10,8,13,21,20,21,11,7,20,16,26,18,12,21,23,19,17,17,27,25,28,23,17,12,20,14,13,13,23,13,22,13,23,24,27,25,18,23,9,16,12,23,26,26,16,10,18,19,20,13,16,21,17,19,25,20,24,25,14,23,8,9,25,16,23,21,13,17,6,8,26,28,8,16,7,18,17,21,13,22,24,18,8,23,22,18,14,23,22,23,29,12,19,20,24,12,16,23,16,23,17,15,15,26,25,19,20,22,21,17,17,22,11,8,17,24,24,24,13,17,23,23,23,15,12,23,23,23,23,19,15,18,23,21,15,18,22,18,16,15,13,26,26,5,11,12,25,19,20,27,5,26,16,19,25,27,15,24,16,23,23,13,15,13,9,15,26,27,23,24,12,10,21,14,30,19,20,17,17,15,22,24,16,22,13,23,22,15,12,11,12,13,13,15,9,19,21,23,22,21,15,13,19,20,20,23,20,9,23,12,20,17,9,22,20,24,21,19,22,18,30,32,5,15,26,11,27,18,26,22,26,26,22,13,3,25,25,20,31,12,19,6,16,20,26,16,15,28,16,16,16,21,11,22,23,9,22,14,22,14,15,9,26,8,24,11,16,20,18,37,20,13,19,23,26,25,9,24,14,20,16,22,23,24,11,15,16,26,24,8,21,17,24,25,19,7,13,23,26,25,14,25,23,15,9,25,9,10,23,22,23,22,22,17,15,22,16,24,26,25,22,22,26,25,12,25,20,19,20,30,13,26,23,13,23,19,16,11,23,19,16,24,28,26,18,24,19,15,19,25,4,23,25,21,16,23,18,19,26,32,33,15,24,25,10,15,7,36,30,4,16,23,16,16,12,16,16,16,16,15,16,16,16,16,22,27,21,23,18,9,29,12,33,26,19,4,11,13,21,24,4,6,8,11,24,22,7,7,29,57,7,15,12,14,12,31,17,4,9,7,9,8,3,26,7,24,7,8,10,11,28,25,25,24,21,31,18,18,26,28,28,17,16,25,24,19,15,25,27,11,27,20,15,13,20,24,12,13,11,13,8,13,13,28,18,20,23,5,26,29,10,11,18,11,13,19,18,19,45,12,24,19,13,19,26,12,10,17,20,14,26,35,23,30,6,11,6,6,4,24,30,8,2,8,35,15,6,17,13,12,21,20,13,17,20,23,3,16,16,7,27,22,16,23,27,27,17,20,27,32,21,27,28,10,24,26,21,30,27,29,12,11,23,24,18,9,20,21,24,19,9,25,12,30,13,26,13,23,22,15,12,28,6,9,24,21,7,8,26,22,5,21,21,21,14,18,19,18,17,21,21,18,9,24,21,23,22,21,17,17,25,20,23,20,25,22,20,25,21,20,25,14,25,12,13,26,13,13,10,21,23,26,17,16,27,28,23,25,16,23,20,29,26,24,27,28,19,14,13,25,12,25,11,23,23,23,16,25,28,23,24,18,10,21,21,22,22,27,23,21,17,19,27,15,27,14,16,23,17,19,9,5,26,11,25,27,20,25,13,26,11,12,23,21,9,12,25,13,21,24,12,16,29,22,10,16,10,23,23,24,13,17,23,13,27,24,22,23,22,19,13,23,24,13,6,15,19,16,28,30,10,22,21,12,30,28,22,17,28,16,18,16,24,22,21,25,26,21,21,19,23,18,27,27,27,25,3,20,19,13,22,14,22,19,27,4,4,27,30,22,11,10,16,18,16,23,26,19,29,20,20,14,28,11,29,20,17,22,9,29,18,4,30,15,18,26,16,25,24,9,34,14,10,20,16,18,20,27,17,24,28,26,21,29,10,27,27,15,27,29,27,28,28,29,15,25,20,13,10,23,13,25,26,14,26,22,18,23,16,27,24,31,14,23,12,18,19,26,29,25,23,14,17,27,14,20,21,18,28,27,6,28,19,25,15,28,18,20,32,11,27,12,18,11,27,32,24,26,19,29,20,20,14,7,20,14,20,18,10,29,4,25,4,22,12,28,25,24,18,17,17,12,21,24,10,21,21,18,8,17,15,22,12,28,9,20,21,19,25,15,18,21,15,25,15,12,19,15,21,10,21,28,13,21,7,27,26,19,25,18,23,11,29,30,23,19,29,25,19,16,15,14,22,19,18,22,27,20,18,19,16,19,15,5,11,15,24,22,24,10,26,14,26,12,35,12,33,7,27,28,12,12,20,31,21,14,19,5,18,28,24,19,12,27,31,16,9,22,25,24,26,16,23,22,24,6,6,28,16,13,36,30,15,17,18,25,13,25,27,27,8,25,12,34,17,8,11,27,27,20,6,14,27,22,29,8,12,15,17,30,15,16,27,18,8,25,14,16,12,13,20,14,23,13,14,13,24,20,17,25,23,21,11,20,23,18,21,22,9,6,12,25,11,23,20,28,28,2,31,6,25,27,20,18,29,28,15,13,30,12,32,21,41,29,29,8,15,27,17,11,16,17,10,6,26,10,23,17,23,25,10,23,25,16,23,21,14,34,29,18,16,15,25,16,30,21,9,20,12,12,24,27,29,8,30,8,11,11],\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"x\":0.7,\"y\":0.95},\"title\":{\"text\":\"Distribution of Word Counts\"},\"xaxis\":{\"title\":{\"text\":\"Word Count\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}},\"barmode\":\"overlay\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9c46cd03-033e-4646-ac11-94e4fc79080d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Analyzing the distribution of word counts through an interactive plot\n",
        "import plotly.graph_objects as go\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "train_word_counts = df_train['text'].apply(lambda x: len(word_tokenize(x)))\n",
        "test_word_counts = df_test['text'].apply(lambda x: len(word_tokenize(x)))\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Histogram(x=train_word_counts, nbinsx=50, opacity=0.5, name='Train'))\n",
        "fig.add_trace(go.Histogram(x=test_word_counts, nbinsx=50, opacity=0.5, name='Test'))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Distribution of Word Counts',\n",
        "    xaxis=dict(title='Word Count'),\n",
        "    yaxis=dict(title='Frequency'),\n",
        "    barmode='overlay',\n",
        "    legend=dict(x=0.7, y=0.95)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yca_tnSom1HP",
        "outputId": "b196a62b-a613-4cae-ca33-a0103a450f90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most complex string in df_train, along with its target value and grade level:\n",
            "\n",
            "#Pandemonium.iso psp http://t.co/HbpNFOAwII\n",
            "Target value: 0\n",
            "Flesch-Kincaid Grade Level: 32.8\n",
            "-----------\n",
            "\n",
            "The least complex string in df_train, along with its target value and grade level:\n",
            "\n",
            "LOOOOOOL\n",
            "Target value: 0\n",
            "Flesch-Kincaid Grade Level: -3.5\n",
            "-----------\n",
            "\n",
            "Average grade level in df_train: 8.020267962695389\n",
            "Average grade level in df_test: 8.063806313208703\n"
          ]
        }
      ],
      "source": [
        "import textstat\n",
        "\n",
        "# Calculate complexity of tweets using Flesch-Kincaid Grade Level\n",
        "df_train['flesch_kincaid'] = df_train['text'].apply(lambda x: textstat.flesch_kincaid_grade(x))\n",
        "df_test['flesch_kincaid'] = df_test['text'].apply(lambda x: textstat.flesch_kincaid_grade(x))\n",
        "\n",
        "# Find the most and least complex strings based on Flesch-Kincaid Grade Level\n",
        "longest_idx = df_train['flesch_kincaid'].idxmax()\n",
        "shortest_idx = df_train['flesch_kincaid'].idxmin()\n",
        "\n",
        "print(\"The most complex string in df_train, along with its target value and grade level:\\n\")\n",
        "print(df_train['text'][longest_idx])\n",
        "print(\"Target value:\", df_train['target'][longest_idx])\n",
        "print(\"Flesch-Kincaid Grade Level:\", df_train['flesch_kincaid'][longest_idx])\n",
        "print(\"-----------\\n\")\n",
        "print(\"The least complex string in df_train, along with its target value and grade level:\\n\")\n",
        "print(df_train['text'][shortest_idx])\n",
        "print(\"Target value:\", df_train['target'][shortest_idx])\n",
        "print(\"Flesch-Kincaid Grade Level:\", df_train['flesch_kincaid'][shortest_idx])\n",
        "print(\"-----------\\n\")\n",
        "\n",
        "# Calculate average grade level for df_train and df_test to check whether the two datasets have similar complexity\n",
        "avg_grade_train = df_train['flesch_kincaid'].mean()\n",
        "avg_grade_test = df_test['flesch_kincaid'].mean()\n",
        "\n",
        "print(\"Average grade level in df_train:\", avg_grade_train)\n",
        "print(\"Average grade level in df_test:\", avg_grade_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observing the average grade level for the train and test dataframes above, we can see that the two datasets have similar distributions in terms of the grade level of the texts. This indicates that the texts in the test dataset are representative of the texts in the training dataset in terms of their complexity and difficulty."
      ],
      "metadata": {
        "id": "REomj9pSQGwl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYLivJusm1Bl"
      },
      "outputs": [],
      "source": [
        "#extracting the text data and labels from the respective DataFrames \n",
        "df_train_text = df_train.text.values\n",
        "df_train_labels = df_train.target.values\n",
        "df_test_text = df_test.text.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lxV9IiSDcek"
      },
      "source": [
        "## Data Cleaning and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the number of unique words in the original training dataset\n",
        "unique_words = set()\n",
        "\n",
        "for row in df_train_text:\n",
        "    words = row.split()\n",
        "    unique_words.update(words)\n",
        "\n",
        "num_unique_words = len(unique_words)\n",
        "\n",
        "print(\"Number of unique words before cleaning:\", num_unique_words)\n"
      ],
      "metadata": {
        "id": "NdmPfyR3jLiW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cdf4c4b-b84a-4f50-e68c-fa327c405a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words before cleaning: 31924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_i1qZHhzzDZ"
      },
      "source": [
        "## Using NLTK library to clean and preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYDYnBXfzw2c",
        "outputId": "2539dcfe-b001-4dc6-956b-5f7fe15b4ff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before cleaning: Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
            "After cleaning: deed reason earthquak may allah forgiv u\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(training_data):\n",
        "    processed_data = []\n",
        "\n",
        "    for sentence in training_data:\n",
        "        sentence = re.sub('<[^>]*>', '', sentence) #Removing HTML tags\n",
        "        sentence = re.sub(r'http\\S+', '', sentence) #Removing URLs\n",
        "        sentence = re.sub(r'[^\\w\\s]', '', sentence) #Removing punctuations\n",
        "        words = nltk.word_tokenize(sentence.lower()) #Tokenizing the sentence into words\n",
        "        \n",
        "        #Lemmatizing, stemming and removing stopwords and non-alphabetic characters\n",
        "        processed_words = [lemmatizer.lemmatize(stemmer.stem(word)) for word in words if word.isalpha() and word not in stop_words]\n",
        "        processed_sentence = \" \".join(processed_words) #Joining the processed words back into a sentence\n",
        "        processed_data.append(processed_sentence)\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "print(\"Before cleaning:\", df_train_text[0])\n",
        "df_train_text = preprocess_text(df_train_text)\n",
        "print(\"After cleaning:\", df_train_text[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating an interactive bar plot to visualize the frequency distribution of words in the preprocessed text\n",
        "\n",
        "import nltk\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_word_frequencies(preprocessed_text):\n",
        "    text = ' '.join(preprocessed_text)\n",
        "    words = nltk.word_tokenize(text)\n",
        "    word_freq = nltk.FreqDist(words)\n",
        "    most_common_words = word_freq.most_common(10)  # 10 is the number of words to be displayed \n",
        "    words = [word[0] for word in most_common_words]\n",
        "    frequencies = [freq[1] for freq in most_common_words]\n",
        "\n",
        "    #Creating a bar plot\n",
        "    fig = go.Figure(data=[go.Bar(x=words, y=frequencies)])\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='Most Common Words after preprocessing',\n",
        "        xaxis_title='Words',\n",
        "        yaxis_title='Frequency',\n",
        "        xaxis=dict(tickangle=-45)\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "plot_word_frequencies(df_train_text)\n",
        "#Reference: https://blog.quantinsti.com/spacy-python/\n",
        "#Reference: https://www.geeksforgeeks.org/python-stemming-words-with-nltk/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "FL58F89A8neS",
        "outputId": "950af518-187e-4f66-cc71-204cfebe828c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"2e35f395-eee1-47a0-9691-0094a29c0335\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2e35f395-eee1-47a0-9691-0094a29c0335\")) {                    Plotly.newPlot(                        \"2e35f395-eee1-47a0-9691-0094a29c0335\",                        [{\"x\":[\"like\",\"fire\",\"get\",\"im\",\"amp\",\"u\",\"bomb\",\"new\",\"via\",\"one\"],\"y\":[408,357,311,300,298,246,230,224,220,204],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"title\":{\"text\":\"Words\"},\"tickangle\":-45},\"title\":{\"text\":\"Most Common Words after preprocessing\"},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2e35f395-eee1-47a0-9691-0094a29c0335');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the number of unique words in the cleaned training dataset\n",
        "unique_words = set()\n",
        "\n",
        "\n",
        "for row in df_train_text:\n",
        "    words = row.split()\n",
        "    unique_words.update(words)\n",
        "\n",
        "\n",
        "num_unique_words = len(unique_words)\n",
        "\n",
        "print(\"Number of unique words after cleaning:\", num_unique_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65vlkvLMi0Wv",
        "outputId": "04416458-fe16-45a8-9021-29975028e290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words after cleaning: 12968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXGrt8Kym00k"
      },
      "outputs": [],
      "source": [
        "#Splitting the training data into training and validation data in the ratio 70:30 for validating our model\n",
        "\n",
        "TRAINING_SPLIT = 0.7\n",
        "\n",
        "def train_val_split(texts, labels, training_split):\n",
        "    train_size = int(len(texts)*training_split)\n",
        "    train_texts = texts[:train_size]\n",
        "    train_labels = labels[:train_size]\n",
        "    validation_texts = texts[train_size:]\n",
        "    validation_labels = labels[train_size:]\n",
        "    return train_texts, validation_texts, train_labels, validation_labels\n",
        "\n",
        "train_texts, val_texts, train_output, val_output = train_val_split(df_train_text, df_train_labels, TRAINING_SPLIT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT60yOF8nMQF"
      },
      "source": [
        "### We fit a tokenizer to the df_train_text dataset to learn the vocabulary and transform the texts into sequences. Then, we pad the sequences to ensure equal length for all sequences. This preprocessing step prepares the text data for modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLSueDcNm6vv"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "NUM_WORDS = num_unique_words\n",
        "OOV_TOKEN = \"<OOV>\"\n",
        "MAXLEN = 120\n",
        "PADDING = 'post'\n",
        "EPOCHS = 15\n",
        "\n",
        "def fit_tokenizer(train_texts, num_words, oov_token):\n",
        "    tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
        "    tokenizer.fit_on_texts(train_texts)\n",
        "    return tokenizer\n",
        "\n",
        "tokenizer = fit_tokenizer(train_texts, NUM_WORDS, OOV_TOKEN)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "def seq_and_pad(texts, tokenizer, padding, maxlen):\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=maxlen, padding=padding)\n",
        "    return padded_sequences\n",
        "\n",
        "train_input = seq_and_pad(train_texts, tokenizer, PADDING, MAXLEN)\n",
        "val_input = seq_and_pad(val_texts, tokenizer, PADDING, MAXLEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5B6d9KLnayU"
      },
      "source": [
        "## Defining an early stopping callback\n",
        "###We don't want to wait for the model to train if a key metric has stopped progressing. Therefore we implement an early stopping callback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHxtj1J4nacF"
      },
      "outputs": [],
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=20)\n",
        "#Reference: https://keras.io/api/callbacks/early_stopping/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g045rh_Vng5P"
      },
      "source": [
        "## Creating our model\n",
        "###Having prepared the explanatory variables, we are ready to build our model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the number of units in input layer and hidden layers\n",
        "# since this is a binary classification problem, we have set the output units to 1\n",
        "import numpy as np\n",
        "\n",
        "shape_input = train_input[0].shape  # Calculating the shape of the input data\n",
        "print(shape_input)\n",
        "units_output = 1  \n",
        "\n",
        "# Calculate the ratio of the cube root of the product of the input dimensions to the number of output units.\n",
        "# This ratio is used to determine the number of units in the hidden layers.\n",
        "\n",
        "ratio = np.cbrt(np.prod(shape_input) / units_output)\n",
        "units_layer1 = int(units_output * ratio * ratio)\n",
        "units_layer2 = int(units_output * ratio)\n",
        "\n",
        "# Calculating the product of the shape_input to determine the size of the input layer\n",
        "np.prod(shape_input), units_layer1, units_layer2, units_output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr0Z5kCX1xYm",
        "outputId": "b5e85487-e638-4fea-89c6-97643a4843a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 24, 4, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZNct87cm6qA"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "def create_model(num_words, embedding_dim, maxlen, func, lr_schedule):\n",
        "    tf.random.set_seed(seed)\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(num_words, embedding_dim, input_length=maxlen), #embedding layer\n",
        "        tf.keras.layers.Flatten(input_shape=(shape_input)), #flattening the input layer\n",
        "        tf.keras.layers.Dense(units_layer1, activation=func), #hidden layer 1\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(units_layer2, activation=func, kernel_regularizer=l2(0.001)), #hidden layer 2\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid') #output layer\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule) #creating an instance of the RMSprop optimizer\n",
        "    \n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "#Reference: https://keras.io/api/layers/regularizers/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = []\n",
        "embedding_dims = range(100,400,50) \n",
        "activation_functions= ['relu','elu','sigmoid']\n",
        "BATCH_SIZES = [30,50,100]\n",
        "accuracy_values = []"
      ],
      "metadata": {
        "id": "_X2ICINrzVDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_size in BATCH_SIZES:\n",
        "  for func in activation_functions:\n",
        "    for embedding_dim in embedding_dims:\n",
        "        initial_learning_rate = 0.01\n",
        "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=1000, decay_rate=0.5, staircase=True)\n",
        "        model = create_model(NUM_WORDS, embedding_dim, MAXLEN, func,lr_schedule )\n",
        "        #Fitting the model to training data for a variation of embedding dimensions, activation functions and batch sizes\n",
        "        history = model.fit(train_input, train_output, epochs=EPOCHS, batch_size=batch_size, validation_data=(val_input, val_output), callbacks=[early_stopping])\n",
        "        accuracy = history.history['val_accuracy'][-1]\n",
        "        accuracy_values.append(accuracy)\n",
        "        models.append([model, batch_size, func, embedding_dim])\n",
        "\n",
        "#Reference: https://keras.io/api/layers/core_layers/embedding/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ64ExbczBNg",
        "outputId": "c0c44717-30d1-4527-e568-5e07f4f508da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "178/178 [==============================] - 6s 25ms/step - loss: 0.6879 - accuracy: 0.5748 - val_loss: 0.6886 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 7s 38ms/step - loss: 0.6828 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 5s 27ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 4s 21ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 3s 16ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 3s 16ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 4s 20ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 3s 18ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 3s 15ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 3s 17ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 4s 21ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 3s 18ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 3s 16ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 3s 16ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 6s 30ms/step - loss: 0.7041 - accuracy: 0.5735 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 5s 27ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 4s 22ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 5s 28ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 4s 21ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 5s 28ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 4s 22ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 5s 27ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 5s 26ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 8s 40ms/step - loss: 0.7911 - accuracy: 0.5748 - val_loss: 0.6889 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 5s 28ms/step - loss: 0.6972 - accuracy: 0.5742 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 6s 31ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 5s 26ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 6s 33ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 5s 27ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 5s 27ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 6s 32ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 5s 27ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 6s 32ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 5s 26ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 7s 39ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 8s 47ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 6s 31ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 5s 29ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 7s 36ms/step - loss: 0.7196 - accuracy: 0.5731 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 6s 34ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 6s 35ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 6s 34ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 5s 31ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 7s 38ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 6s 31ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 7s 37ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 6s 32ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 7s 37ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 6s 33ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 6s 36ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 6s 32ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 7s 37ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 6s 32ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 8s 40ms/step - loss: 0.7367 - accuracy: 0.5748 - val_loss: 0.6910 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 8s 43ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 7s 37ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 9s 48ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 7s 39ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 8s 44ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 7s 40ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 7s 37ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 8s 43ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 6s 34ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 8s 44ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 7s 38ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 8s 44ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 7s 38ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 8s 44ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 10s 52ms/step - loss: 0.8104 - accuracy: 0.5708 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 7s 42ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 8s 47ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 8s 46ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 8s 44ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 9s 49ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 8s 43ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 9s 48ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 9s 50ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 8s 43ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 9s 48ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 8s 46ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 8s 43ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 9s 48ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 8s 45ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 4s 16ms/step - loss: 0.7551 - accuracy: 0.5418 - val_loss: 0.6908 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 4s 20ms/step - loss: 0.6859 - accuracy: 0.5740 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 3s 15ms/step - loss: 0.6849 - accuracy: 0.5746 - val_loss: 0.6914 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 3s 15ms/step - loss: 0.6844 - accuracy: 0.5731 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 3s 15ms/step - loss: 0.6832 - accuracy: 0.5748 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 3s 18ms/step - loss: 0.6830 - accuracy: 0.5752 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 3s 17ms/step - loss: 0.6827 - accuracy: 0.5753 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 3s 14ms/step - loss: 0.6822 - accuracy: 0.5753 - val_loss: 0.6855 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 3s 14ms/step - loss: 0.6427 - accuracy: 0.6230 - val_loss: 0.5775 - val_accuracy: 0.7207\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 3s 14ms/step - loss: 0.4836 - accuracy: 0.7971 - val_loss: 0.5286 - val_accuracy: 0.7312\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.3406 - accuracy: 0.8885 - val_loss: 0.5499 - val_accuracy: 0.7329\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 3s 15ms/step - loss: 0.2440 - accuracy: 0.9309 - val_loss: 0.6813 - val_accuracy: 0.7049\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 3s 15ms/step - loss: 0.2007 - accuracy: 0.9354 - val_loss: 0.7636 - val_accuracy: 0.6712\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 3s 15ms/step - loss: 0.1801 - accuracy: 0.9409 - val_loss: 0.7710 - val_accuracy: 0.7023\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 3s 15ms/step - loss: 0.1613 - accuracy: 0.9384 - val_loss: 0.9485 - val_accuracy: 0.6918\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 5s 22ms/step - loss: 0.9007 - accuracy: 0.5155 - val_loss: 0.6930 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.6873 - accuracy: 0.5714 - val_loss: 0.6922 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.6843 - accuracy: 0.5737 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 4s 25ms/step - loss: 0.6858 - accuracy: 0.5761 - val_loss: 0.6886 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.6850 - accuracy: 0.5738 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.6828 - accuracy: 0.5753 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 4s 24ms/step - loss: 0.6826 - accuracy: 0.5757 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 4s 21ms/step - loss: 0.6827 - accuracy: 0.5748 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 3s 20ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6887 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 5s 26ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 3s 18ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 4s 21ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6884 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 7s 32ms/step - loss: 1.0398 - accuracy: 0.5177 - val_loss: 0.6902 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 4s 25ms/step - loss: 0.6925 - accuracy: 0.5690 - val_loss: 0.6910 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 4s 25ms/step - loss: 0.6843 - accuracy: 0.5746 - val_loss: 0.7172 - val_accuracy: 0.4418\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 5s 31ms/step - loss: 0.6842 - accuracy: 0.5735 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 4s 24ms/step - loss: 0.6835 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 4s 24ms/step - loss: 0.6828 - accuracy: 0.5750 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 5s 29ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 4s 24ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 5s 27ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 5s 28ms/step - loss: 0.6821 - accuracy: 0.5753 - val_loss: 0.6893 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 4s 25ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 6s 31ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6849 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 4s 25ms/step - loss: 0.6795 - accuracy: 0.5750 - val_loss: 0.6846 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 7s 38ms/step - loss: 0.6386 - accuracy: 0.6360 - val_loss: 0.5835 - val_accuracy: 0.7237\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 6s 34ms/step - loss: 0.4818 - accuracy: 0.7958 - val_loss: 0.5248 - val_accuracy: 0.7482\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 7s 35ms/step - loss: 0.7617 - accuracy: 0.5410 - val_loss: 0.6904 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 6s 32ms/step - loss: 0.6850 - accuracy: 0.5755 - val_loss: 0.6954 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 6s 36ms/step - loss: 0.6856 - accuracy: 0.5746 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 5s 30ms/step - loss: 0.6845 - accuracy: 0.5737 - val_loss: 0.6913 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 6s 36ms/step - loss: 0.6864 - accuracy: 0.5740 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 6s 31ms/step - loss: 0.6852 - accuracy: 0.5722 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 6s 36ms/step - loss: 0.6827 - accuracy: 0.5742 - val_loss: 0.6884 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 6s 32ms/step - loss: 0.6828 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 7s 37ms/step - loss: 0.6829 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 6s 31ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 6s 35ms/step - loss: 0.6830 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 6s 33ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 6s 34ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6902 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 6s 34ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 6s 33ms/step - loss: 0.6816 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 8s 42ms/step - loss: 0.8143 - accuracy: 0.5288 - val_loss: 0.6945 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 6s 36ms/step - loss: 0.6874 - accuracy: 0.5755 - val_loss: 0.6885 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 7s 42ms/step - loss: 0.6842 - accuracy: 0.5748 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 6s 36ms/step - loss: 0.6844 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 8s 42ms/step - loss: 0.6834 - accuracy: 0.5765 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 7s 38ms/step - loss: 0.6827 - accuracy: 0.5757 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 8s 43ms/step - loss: 0.6827 - accuracy: 0.5757 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 6s 36ms/step - loss: 0.6825 - accuracy: 0.5752 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 8s 43ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 6s 36ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6889 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 7s 42ms/step - loss: 0.6827 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 7s 37ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 7s 40ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 7s 42ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 7s 39ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 10s 49ms/step - loss: 0.7213 - accuracy: 0.5478 - val_loss: 0.6894 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 8s 46ms/step - loss: 0.6861 - accuracy: 0.5752 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 8s 43ms/step - loss: 0.6842 - accuracy: 0.5768 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 8s 47ms/step - loss: 0.6836 - accuracy: 0.5744 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 8s 42ms/step - loss: 0.6842 - accuracy: 0.5735 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 9s 49ms/step - loss: 0.6827 - accuracy: 0.5759 - val_loss: 0.6883 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 8s 48ms/step - loss: 0.6829 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 8s 43ms/step - loss: 0.6827 - accuracy: 0.5753 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 9s 49ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 9s 48ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6892 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 8s 43ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 9s 48ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 8s 42ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 8s 47ms/step - loss: 0.6820 - accuracy: 0.5748 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 8s 45ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6889 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 5s 22ms/step - loss: 0.6960 - accuracy: 0.5598 - val_loss: 0.6922 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 3s 15ms/step - loss: 0.6852 - accuracy: 0.5738 - val_loss: 0.6895 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 3s 15ms/step - loss: 0.6836 - accuracy: 0.5753 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 3s 15ms/step - loss: 0.6833 - accuracy: 0.5755 - val_loss: 0.6886 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 3s 17ms/step - loss: 0.6827 - accuracy: 0.5753 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 3s 15ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 3s 14ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6864 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 3s 16ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 4s 21ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6886 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 3s 14ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 3s 15ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 3s 15ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 3s 18ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 3s 17ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 5s 21ms/step - loss: 0.6920 - accuracy: 0.5637 - val_loss: 0.6909 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.6850 - accuracy: 0.5753 - val_loss: 0.6897 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 5s 26ms/step - loss: 0.6834 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.6836 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.6828 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 4s 21ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6864 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 3s 20ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 4s 25ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6887 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 3s 20ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 4s 25ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 4s 20ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 3s 19ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 6s 31ms/step - loss: 0.7004 - accuracy: 0.5459 - val_loss: 0.6920 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 4s 24ms/step - loss: 0.6847 - accuracy: 0.5759 - val_loss: 0.6904 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 5s 27ms/step - loss: 0.6841 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 5s 27ms/step - loss: 0.6827 - accuracy: 0.5755 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 4s 25ms/step - loss: 0.6824 - accuracy: 0.5753 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 5s 30ms/step - loss: 0.6828 - accuracy: 0.5757 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 4s 25ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 4s 25ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6864 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 5s 30ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 4s 24ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6886 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 5s 30ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 4s 24ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 5s 27ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 5s 28ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 7s 34ms/step - loss: 0.6948 - accuracy: 0.5613 - val_loss: 0.6929 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 6s 36ms/step - loss: 0.6851 - accuracy: 0.5752 - val_loss: 0.6896 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 6s 32ms/step - loss: 0.6838 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 7s 38ms/step - loss: 0.6828 - accuracy: 0.5755 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 6s 31ms/step - loss: 0.6826 - accuracy: 0.5759 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 6s 36ms/step - loss: 0.6827 - accuracy: 0.5748 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 6s 34ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 7s 39ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 6s 33ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 7s 38ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6886 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 6s 32ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 6s 36ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 6s 33ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 6s 34ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 6s 34ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 9s 44ms/step - loss: 0.6912 - accuracy: 0.5699 - val_loss: 0.6916 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 6s 36ms/step - loss: 0.6844 - accuracy: 0.5753 - val_loss: 0.6894 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 8s 44ms/step - loss: 0.6830 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 7s 38ms/step - loss: 0.6832 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 7s 41ms/step - loss: 0.6825 - accuracy: 0.5753 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 7s 39ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 7s 39ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 7s 42ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6864 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 7s 37ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 8s 44ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6888 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 7s 37ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 8s 42ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 6s 36ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 8s 43ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 7s 38ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "178/178 [==============================] - 10s 47ms/step - loss: 0.6924 - accuracy: 0.5697 - val_loss: 0.6928 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 9s 50ms/step - loss: 0.6853 - accuracy: 0.5748 - val_loss: 0.6895 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 8s 43ms/step - loss: 0.6837 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 9s 48ms/step - loss: 0.6832 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 9s 50ms/step - loss: 0.6828 - accuracy: 0.5753 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 8s 44ms/step - loss: 0.6826 - accuracy: 0.5757 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 9s 49ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 9s 49ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 7s 42ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 9s 49ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6887 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 8s 44ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 8s 46ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 9s 50ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 8s 44ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 8s 47ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 4s 27ms/step - loss: 0.7171 - accuracy: 0.5750 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 2s 18ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 2s 20ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 2s 18ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6864 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 3s 27ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 2s 20ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 4s 26ms/step - loss: 0.6993 - accuracy: 0.5729 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 3s 23ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6864 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 3s 28ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 0.7318 - accuracy: 0.5688 - val_loss: 0.6886 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 3s 29ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 3s 29ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6864 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 3s 29ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 5s 40ms/step - loss: 0.7323 - accuracy: 0.5691 - val_loss: 0.6884 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6864 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 7s 56ms/step - loss: 0.7208 - accuracy: 0.5714 - val_loss: 0.6886 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 6s 55ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6864 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 6s 53ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 5s 50ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 7s 53ms/step - loss: 0.7948 - accuracy: 0.5735 - val_loss: 0.6890 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 6s 53ms/step - loss: 0.6829 - accuracy: 0.5753 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 6s 58ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 7s 64ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 6s 53ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6864 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 6s 54ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 6s 59ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 6s 56ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 6s 51ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 4s 26ms/step - loss: 0.8476 - accuracy: 0.5144 - val_loss: 0.6930 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 2s 18ms/step - loss: 0.6952 - accuracy: 0.5588 - val_loss: 0.6887 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 2s 18ms/step - loss: 0.6838 - accuracy: 0.5752 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 2s 18ms/step - loss: 0.6832 - accuracy: 0.5746 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.6707 - accuracy: 0.5892 - val_loss: 0.6064 - val_accuracy: 0.7014\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.5314 - accuracy: 0.7696 - val_loss: 0.5388 - val_accuracy: 0.7474\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 3s 26ms/step - loss: 0.3812 - accuracy: 0.8619 - val_loss: 0.5533 - val_accuracy: 0.7356\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.2697 - accuracy: 0.9112 - val_loss: 0.6863 - val_accuracy: 0.7128\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 2s 18ms/step - loss: 0.2284 - accuracy: 0.9278 - val_loss: 0.7471 - val_accuracy: 0.6870\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.1882 - accuracy: 0.9323 - val_loss: 0.8922 - val_accuracy: 0.6725\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.1396 - accuracy: 0.9415 - val_loss: 0.7360 - val_accuracy: 0.7189\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.1341 - accuracy: 0.9467 - val_loss: 0.7675 - val_accuracy: 0.7180\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.1402 - accuracy: 0.9379 - val_loss: 0.9928 - val_accuracy: 0.6699\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 2s 22ms/step - loss: 0.1272 - accuracy: 0.9409 - val_loss: 1.1465 - val_accuracy: 0.7045\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.1280 - accuracy: 0.9529 - val_loss: 1.2706 - val_accuracy: 0.6607\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 4s 26ms/step - loss: 1.0571 - accuracy: 0.5057 - val_loss: 0.6935 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.7050 - accuracy: 0.5611 - val_loss: 0.6906 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 0.6871 - accuracy: 0.5735 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.6834 - accuracy: 0.5738 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.6844 - accuracy: 0.5735 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.6842 - accuracy: 0.5744 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.6836 - accuracy: 0.5733 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 0.6820 - accuracy: 0.5782 - val_loss: 0.6763 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.5727 - accuracy: 0.7114 - val_loss: 0.6352 - val_accuracy: 0.6699\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.4252 - accuracy: 0.8230 - val_loss: 0.5244 - val_accuracy: 0.7373\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 2s 23ms/step - loss: 0.2969 - accuracy: 0.8820 - val_loss: 0.5828 - val_accuracy: 0.7456\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.2348 - accuracy: 0.9276 - val_loss: 0.6376 - val_accuracy: 0.7382\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 0.1963 - accuracy: 0.9392 - val_loss: 0.7895 - val_accuracy: 0.7360\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 2s 23ms/step - loss: 0.1816 - accuracy: 0.9409 - val_loss: 0.8902 - val_accuracy: 0.7229\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 2s 23ms/step - loss: 0.1718 - accuracy: 0.9482 - val_loss: 0.8661 - val_accuracy: 0.7264\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 4s 32ms/step - loss: 0.9155 - accuracy: 0.5130 - val_loss: 0.6964 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.6956 - accuracy: 0.5534 - val_loss: 0.6900 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 0.6855 - accuracy: 0.5723 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 0.6841 - accuracy: 0.5733 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 0.6831 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.6831 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 0.6832 - accuracy: 0.5748 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 0.6823 - accuracy: 0.5763 - val_loss: 0.6897 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.6782 - accuracy: 0.5765 - val_loss: 0.6195 - val_accuracy: 0.7242\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5610 - accuracy: 0.7287 - val_loss: 0.5559 - val_accuracy: 0.7294\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.4137 - accuracy: 0.8341 - val_loss: 0.5286 - val_accuracy: 0.7290\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 0.3106 - accuracy: 0.9064 - val_loss: 0.6113 - val_accuracy: 0.7229\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.2475 - accuracy: 0.9274 - val_loss: 0.7351 - val_accuracy: 0.6913\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 0.2004 - accuracy: 0.9413 - val_loss: 0.7835 - val_accuracy: 0.7010\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 0.1917 - accuracy: 0.9452 - val_loss: 0.8990 - val_accuracy: 0.7150\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 5s 38ms/step - loss: 0.8462 - accuracy: 0.5181 - val_loss: 0.6932 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.6946 - accuracy: 0.5618 - val_loss: 0.6895 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.6850 - accuracy: 0.5714 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.6863 - accuracy: 0.5755 - val_loss: 0.6889 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 0.6835 - accuracy: 0.5748 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.6840 - accuracy: 0.5731 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.6828 - accuracy: 0.5753 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 0.6827 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.6830 - accuracy: 0.5752 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.6817 - accuracy: 0.5757 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 6s 48ms/step - loss: 0.9085 - accuracy: 0.5318 - val_loss: 0.6924 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.6936 - accuracy: 0.5506 - val_loss: 0.6890 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 0.6851 - accuracy: 0.5693 - val_loss: 0.7077 - val_accuracy: 0.4418\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.6856 - accuracy: 0.5735 - val_loss: 0.6886 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.6851 - accuracy: 0.5757 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 6s 54ms/step - loss: 0.6858 - accuracy: 0.5746 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.6831 - accuracy: 0.5746 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.6832 - accuracy: 0.5725 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 0.6834 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.6820 - accuracy: 0.5748 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 6s 53ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6887 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 7s 56ms/step - loss: 0.7901 - accuracy: 0.5234 - val_loss: 0.6898 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 7s 63ms/step - loss: 0.6872 - accuracy: 0.5720 - val_loss: 0.6894 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 5s 51ms/step - loss: 0.6868 - accuracy: 0.5738 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 6s 57ms/step - loss: 0.6837 - accuracy: 0.5722 - val_loss: 0.6883 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 5s 50ms/step - loss: 0.6841 - accuracy: 0.5740 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 0.6828 - accuracy: 0.5752 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 6s 61ms/step - loss: 0.6832 - accuracy: 0.5731 - val_loss: 0.6894 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 5s 50ms/step - loss: 0.6830 - accuracy: 0.5753 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 0.6831 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6886 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 6s 57ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 6s 54ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 5s 51ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 6s 61ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6893 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 3s 20ms/step - loss: 0.6959 - accuracy: 0.5577 - val_loss: 0.6910 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.6865 - accuracy: 0.5742 - val_loss: 0.6895 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 2s 22ms/step - loss: 0.6849 - accuracy: 0.5753 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 2s 23ms/step - loss: 0.6838 - accuracy: 0.5755 - val_loss: 0.6888 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.6831 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.6830 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.6827 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 3s 23ms/step - loss: 0.6816 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 2s 21ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.6817 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 2s 18ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 4s 30ms/step - loss: 0.6917 - accuracy: 0.5645 - val_loss: 0.6909 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 0.6843 - accuracy: 0.5748 - val_loss: 0.6894 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.6836 - accuracy: 0.5746 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.6832 - accuracy: 0.5755 - val_loss: 0.6886 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.6828 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 0.6827 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 3s 29ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.6816 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 3s 27ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 3s 24ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 5s 36ms/step - loss: 0.6880 - accuracy: 0.5729 - val_loss: 0.6908 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.6832 - accuracy: 0.5755 - val_loss: 0.6885 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.6833 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.6831 - accuracy: 0.5755 - val_loss: 0.6883 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 0.6827 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.6816 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.6817 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 6s 40ms/step - loss: 0.6920 - accuracy: 0.5622 - val_loss: 0.6913 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.6847 - accuracy: 0.5755 - val_loss: 0.6888 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 0.6837 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.6836 - accuracy: 0.5755 - val_loss: 0.6884 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.6829 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 0.6828 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.6827 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.6816 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.6817 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 6s 47ms/step - loss: 0.6916 - accuracy: 0.5665 - val_loss: 0.6900 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 0.6847 - accuracy: 0.5755 - val_loss: 0.6889 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 5s 51ms/step - loss: 0.6839 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.6835 - accuracy: 0.5755 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 6s 53ms/step - loss: 0.6829 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 6s 56ms/step - loss: 0.6827 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 5s 51ms/step - loss: 0.6817 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 6s 56ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.6817 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.6817 - accuracy: 0.5755 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "107/107 [==============================] - 6s 53ms/step - loss: 0.6945 - accuracy: 0.5637 - val_loss: 0.6928 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 7s 62ms/step - loss: 0.6852 - accuracy: 0.5750 - val_loss: 0.6892 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 5s 50ms/step - loss: 0.6842 - accuracy: 0.5752 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 7s 61ms/step - loss: 0.6836 - accuracy: 0.5755 - val_loss: 0.6890 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 5s 51ms/step - loss: 0.6833 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 6s 55ms/step - loss: 0.6830 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 6s 56ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 5s 50ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 6s 61ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 0.6817 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 6s 55ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 6s 57ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 2s 27ms/step - loss: 0.7989 - accuracy: 0.5738 - val_loss: 0.6897 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.6845 - accuracy: 0.5755 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 2s 30ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 2s 34ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 2s 30ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 2s 36ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 1s 27ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 3s 36ms/step - loss: 0.7566 - accuracy: 0.5722 - val_loss: 0.6887 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6835 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6830 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 2s 31ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 2s 36ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 2s 44ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 2s 36ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 2s 44ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 2s 35ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 3s 42ms/step - loss: 0.8299 - accuracy: 0.5686 - val_loss: 0.6897 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 2s 42ms/step - loss: 0.6839 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 3s 55ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 3s 49ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 2s 42ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 2s 39ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 2s 39ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 2s 39ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 3s 55ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 2s 43ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 2s 39ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 2s 40ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 2s 39ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 2s 41ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 3s 58ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 4s 52ms/step - loss: 0.8249 - accuracy: 0.5727 - val_loss: 0.6885 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 3s 51ms/step - loss: 0.6831 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 3s 51ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 3s 64ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 3s 59ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 3s 48ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 3s 48ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 3s 49ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 4s 71ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 3s 50ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 3s 50ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 3s 51ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 3s 55ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 4s 66ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 3s 52ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 4s 68ms/step - loss: 0.8794 - accuracy: 0.5722 - val_loss: 0.6891 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 4s 77ms/step - loss: 0.6837 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 3s 60ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 3s 58ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 4s 66ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 4s 73ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 3s 58ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 3s 59ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 4s 66ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 4s 73ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 3s 58ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 3s 59ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 3s 63ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 4s 75ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 3s 61ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 5s 75ms/step - loss: 0.7032 - accuracy: 0.5731 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 5s 90ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 4s 71ms/step - loss: 0.6824 - accuracy: 0.5748 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 4s 70ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 5s 91ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 4s 71ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 4s 70ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 4s 83ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 4s 75ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 4s 68ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 4s 69ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 5s 85ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 4s 68ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 4s 67ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 5s 91ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 2s 28ms/step - loss: 0.8469 - accuracy: 0.5194 - val_loss: 0.6947 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.6611 - accuracy: 0.6181 - val_loss: 0.5733 - val_accuracy: 0.7123\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.4648 - accuracy: 0.8135 - val_loss: 0.6903 - val_accuracy: 0.6217\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3220 - accuracy: 0.8974 - val_loss: 0.5918 - val_accuracy: 0.7211\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.2478 - accuracy: 0.9263 - val_loss: 0.6294 - val_accuracy: 0.7163\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.2067 - accuracy: 0.9384 - val_loss: 0.7298 - val_accuracy: 0.7207\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 1s 27ms/step - loss: 0.1915 - accuracy: 0.9413 - val_loss: 0.7943 - val_accuracy: 0.7080\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 2s 37ms/step - loss: 0.1547 - accuracy: 0.9497 - val_loss: 0.7547 - val_accuracy: 0.7053\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 2s 30ms/step - loss: 0.1456 - accuracy: 0.9565 - val_loss: 1.0793 - val_accuracy: 0.7172\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.1455 - accuracy: 0.9475 - val_loss: 1.0378 - val_accuracy: 0.6957\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.1362 - accuracy: 0.9495 - val_loss: 0.7477 - val_accuracy: 0.7115\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.1338 - accuracy: 0.9523 - val_loss: 0.8523 - val_accuracy: 0.7259\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.1243 - accuracy: 0.9503 - val_loss: 1.1216 - val_accuracy: 0.7145\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.1155 - accuracy: 0.9518 - val_loss: 1.1826 - val_accuracy: 0.7123\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.1217 - accuracy: 0.9505 - val_loss: 1.3834 - val_accuracy: 0.7071\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 3s 36ms/step - loss: 1.1204 - accuracy: 0.5112 - val_loss: 0.6917 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 2s 35ms/step - loss: 0.7431 - accuracy: 0.5226 - val_loss: 0.6906 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 2s 44ms/step - loss: 0.6956 - accuracy: 0.5570 - val_loss: 0.6885 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 2s 38ms/step - loss: 0.6841 - accuracy: 0.5753 - val_loss: 0.6892 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6835 - accuracy: 0.5755 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 2s 33ms/step - loss: 0.6853 - accuracy: 0.5695 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 2s 33ms/step - loss: 0.6834 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6827 - accuracy: 0.5746 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 2s 33ms/step - loss: 0.6829 - accuracy: 0.5742 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 2s 44ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 2s 39ms/step - loss: 0.6827 - accuracy: 0.5746 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6840 - accuracy: 0.5753 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6834 - accuracy: 0.5722 - val_loss: 0.6905 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6826 - accuracy: 0.5746 - val_loss: 0.6909 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.7089 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 4s 51ms/step - loss: 1.0851 - accuracy: 0.5061 - val_loss: 0.6913 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 3s 54ms/step - loss: 0.7241 - accuracy: 0.5357 - val_loss: 0.6936 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 2s 42ms/step - loss: 0.6904 - accuracy: 0.5710 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 2s 39ms/step - loss: 0.6835 - accuracy: 0.5757 - val_loss: 0.6883 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 2s 39ms/step - loss: 0.6832 - accuracy: 0.5752 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 2s 39ms/step - loss: 0.6827 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 3s 51ms/step - loss: 0.6827 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 3s 52ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 2s 39ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6883 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 2s 41ms/step - loss: 0.6822 - accuracy: 0.5746 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 2s 39ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 2s 42ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 3s 53ms/step - loss: 0.6825 - accuracy: 0.5742 - val_loss: 0.6893 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 3s 49ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6886 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 2s 39ms/step - loss: 0.6823 - accuracy: 0.5753 - val_loss: 0.6906 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 4s 55ms/step - loss: 0.8882 - accuracy: 0.5284 - val_loss: 0.6947 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 3s 51ms/step - loss: 0.7151 - accuracy: 0.5262 - val_loss: 0.6902 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 4s 69ms/step - loss: 0.6881 - accuracy: 0.5598 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 3s 55ms/step - loss: 0.6851 - accuracy: 0.5731 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 3s 50ms/step - loss: 0.6831 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 3s 50ms/step - loss: 0.6828 - accuracy: 0.5744 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 3s 53ms/step - loss: 0.6833 - accuracy: 0.5729 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 4s 72ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 3s 49ms/step - loss: 0.6829 - accuracy: 0.5755 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 3s 48ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 2s 46ms/step - loss: 0.6829 - accuracy: 0.5738 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 0.6823 - accuracy: 0.5759 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 3s 64ms/step - loss: 0.6828 - accuracy: 0.5757 - val_loss: 0.6887 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 3s 52ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6941 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 3s 50ms/step - loss: 0.6829 - accuracy: 0.5755 - val_loss: 0.7425 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 5s 85ms/step - loss: 1.3954 - accuracy: 0.4984 - val_loss: 0.6910 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 3s 61ms/step - loss: 0.7597 - accuracy: 0.5164 - val_loss: 0.6988 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 3s 59ms/step - loss: 0.6964 - accuracy: 0.5592 - val_loss: 0.6883 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 3s 61ms/step - loss: 0.6847 - accuracy: 0.5731 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 4s 80ms/step - loss: 0.6835 - accuracy: 0.5750 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 3s 59ms/step - loss: 0.6829 - accuracy: 0.5755 - val_loss: 0.6871 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 3s 62ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 4s 67ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 4s 78ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6887 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 3s 62ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 3s 60ms/step - loss: 0.6827 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 4s 67ms/step - loss: 0.6824 - accuracy: 0.5757 - val_loss: 0.6886 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 4s 75ms/step - loss: 0.6825 - accuracy: 0.5735 - val_loss: 0.6899 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 3s 59ms/step - loss: 0.6823 - accuracy: 0.5729 - val_loss: 0.6888 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 3s 60ms/step - loss: 0.6821 - accuracy: 0.5748 - val_loss: 0.6903 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 6s 95ms/step - loss: 1.0888 - accuracy: 0.5204 - val_loss: 0.6923 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 4s 68ms/step - loss: 0.7212 - accuracy: 0.5346 - val_loss: 1.0061 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 4s 70ms/step - loss: 0.6969 - accuracy: 0.5650 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 5s 84ms/step - loss: 0.6839 - accuracy: 0.5742 - val_loss: 0.6870 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 4s 72ms/step - loss: 0.6831 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 4s 67ms/step - loss: 0.6837 - accuracy: 0.5729 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 4s 70ms/step - loss: 0.6838 - accuracy: 0.5742 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 5s 88ms/step - loss: 0.6831 - accuracy: 0.5729 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 4s 71ms/step - loss: 0.6828 - accuracy: 0.5753 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 4s 68ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6889 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 5s 93ms/step - loss: 0.6822 - accuracy: 0.5765 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 4s 70ms/step - loss: 0.6828 - accuracy: 0.5744 - val_loss: 0.6869 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 4s 68ms/step - loss: 0.6841 - accuracy: 0.5737 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 4s 80ms/step - loss: 0.6830 - accuracy: 0.5737 - val_loss: 0.6891 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 4s 76ms/step - loss: 0.6827 - accuracy: 0.5731 - val_loss: 0.6903 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 2s 28ms/step - loss: 0.7008 - accuracy: 0.5487 - val_loss: 0.6915 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.6864 - accuracy: 0.5742 - val_loss: 0.6895 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.6853 - accuracy: 0.5750 - val_loss: 0.6883 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.6842 - accuracy: 0.5759 - val_loss: 0.6887 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.6845 - accuracy: 0.5757 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.6832 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.6834 - accuracy: 0.5755 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 2s 31ms/step - loss: 0.6829 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 2s 34ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6883 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.6828 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6894 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 3s 37ms/step - loss: 0.6958 - accuracy: 0.5575 - val_loss: 0.6901 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 2s 45ms/step - loss: 0.6856 - accuracy: 0.5757 - val_loss: 0.6884 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 2s 39ms/step - loss: 0.6845 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 2s 33ms/step - loss: 0.6845 - accuracy: 0.5755 - val_loss: 0.6883 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 2s 33ms/step - loss: 0.6830 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6833 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 2s 33ms/step - loss: 0.6830 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 2s 33ms/step - loss: 0.6827 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 2s 42ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 2s 45ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6883 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6864 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 2s 33ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 2s 32ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 2s 33ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6895 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 5s 65ms/step - loss: 0.6989 - accuracy: 0.5442 - val_loss: 0.6916 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 2s 43ms/step - loss: 0.6864 - accuracy: 0.5738 - val_loss: 0.6892 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 2s 44ms/step - loss: 0.6841 - accuracy: 0.5746 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 2s 43ms/step - loss: 0.6839 - accuracy: 0.5748 - val_loss: 0.6888 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 2s 41ms/step - loss: 0.6831 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 3s 56ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 3s 49ms/step - loss: 0.6828 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 2s 44ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 2s 41ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 2s 43ms/step - loss: 0.6818 - accuracy: 0.5755 - val_loss: 0.6883 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 2s 44ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 3s 59ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 2s 43ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 2s 41ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 2s 40ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6895 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 5s 71ms/step - loss: 0.6918 - accuracy: 0.5585 - val_loss: 0.6915 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 3s 50ms/step - loss: 0.6861 - accuracy: 0.5753 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 3s 50ms/step - loss: 0.6840 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 3s 51ms/step - loss: 0.6828 - accuracy: 0.5755 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 4s 68ms/step - loss: 0.6829 - accuracy: 0.5755 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 3s 51ms/step - loss: 0.6828 - accuracy: 0.5755 - val_loss: 0.6877 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 3s 52ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6866 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 3s 49ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 4s 69ms/step - loss: 0.6817 - accuracy: 0.5755 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 3s 50ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 3s 52ms/step - loss: 0.6825 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 3s 53ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 3s 52ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6880 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 4s 70ms/step - loss: 0.6820 - accuracy: 0.5755 - val_loss: 0.6895 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 4s 67ms/step - loss: 0.6981 - accuracy: 0.5421 - val_loss: 0.6914 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 3s 62ms/step - loss: 0.6859 - accuracy: 0.5752 - val_loss: 0.6896 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 4s 70ms/step - loss: 0.6839 - accuracy: 0.5750 - val_loss: 0.6878 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 4s 72ms/step - loss: 0.6833 - accuracy: 0.5757 - val_loss: 0.6883 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 3s 63ms/step - loss: 0.6831 - accuracy: 0.5755 - val_loss: 0.6872 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 3s 63ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 4s 74ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 4s 69ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6864 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 3s 62ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 3s 62ms/step - loss: 0.6817 - accuracy: 0.5755 - val_loss: 0.6882 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 4s 76ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 4s 69ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 3s 63ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 3s 64ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 4s 81ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6895 - val_accuracy: 0.5582\n",
            "Epoch 1/15\n",
            "54/54 [==============================] - 5s 76ms/step - loss: 0.6940 - accuracy: 0.5555 - val_loss: 0.6914 - val_accuracy: 0.5582\n",
            "Epoch 2/15\n",
            "54/54 [==============================] - 4s 75ms/step - loss: 0.6842 - accuracy: 0.5740 - val_loss: 0.6887 - val_accuracy: 0.5582\n",
            "Epoch 3/15\n",
            "54/54 [==============================] - 5s 89ms/step - loss: 0.6836 - accuracy: 0.5752 - val_loss: 0.6874 - val_accuracy: 0.5582\n",
            "Epoch 4/15\n",
            "54/54 [==============================] - 4s 69ms/step - loss: 0.6832 - accuracy: 0.5755 - val_loss: 0.6884 - val_accuracy: 0.5582\n",
            "Epoch 5/15\n",
            "54/54 [==============================] - 4s 70ms/step - loss: 0.6827 - accuracy: 0.5755 - val_loss: 0.6876 - val_accuracy: 0.5582\n",
            "Epoch 6/15\n",
            "54/54 [==============================] - 5s 88ms/step - loss: 0.6828 - accuracy: 0.5755 - val_loss: 0.6873 - val_accuracy: 0.5582\n",
            "Epoch 7/15\n",
            "54/54 [==============================] - 4s 78ms/step - loss: 0.6826 - accuracy: 0.5755 - val_loss: 0.6875 - val_accuracy: 0.5582\n",
            "Epoch 8/15\n",
            "54/54 [==============================] - 4s 72ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6864 - val_accuracy: 0.5582\n",
            "Epoch 9/15\n",
            "54/54 [==============================] - 4s 75ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.6879 - val_accuracy: 0.5582\n",
            "Epoch 10/15\n",
            "54/54 [==============================] - 5s 86ms/step - loss: 0.6816 - accuracy: 0.5755 - val_loss: 0.6884 - val_accuracy: 0.5582\n",
            "Epoch 11/15\n",
            "54/54 [==============================] - 4s 70ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6864 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "54/54 [==============================] - 4s 68ms/step - loss: 0.6824 - accuracy: 0.5755 - val_loss: 0.6867 - val_accuracy: 0.5582\n",
            "Epoch 13/15\n",
            "54/54 [==============================] - 5s 90ms/step - loss: 0.6822 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 14/15\n",
            "54/54 [==============================] - 4s 71ms/step - loss: 0.6821 - accuracy: 0.5755 - val_loss: 0.6881 - val_accuracy: 0.5582\n",
            "Epoch 15/15\n",
            "54/54 [==============================] - 4s 69ms/step - loss: 0.6819 - accuracy: 0.5755 - val_loss: 0.6896 - val_accuracy: 0.5582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking accuracies of different variations of the models\n",
        "for i, (model, batch, function, dimension) in enumerate(models):\n",
        "  print(f\"Model {i+1}: for {batch} batches and {function} activation function and {dimension} dimensions we had this accuracy:\")\n",
        "  accuracy = model.evaluate(val_input, val_output)[1]\n",
        "  print(f\"Accuracy: {accuracy:.4f}\\n\")"
      ],
      "metadata": {
        "id": "UZ1vv5a6hyRQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69cd8749-9f43-47a6-b6b7-10a719312951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1: for 30 batches and relu activation function and 100 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 2: for 30 batches and relu activation function and 150 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 3: for 30 batches and relu activation function and 200 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 4: for 30 batches and relu activation function and 250 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6871 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 5: for 30 batches and relu activation function and 300 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6871 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 6: for 30 batches and relu activation function and 350 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6871 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 7: for 30 batches and elu activation function and 100 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9485 - accuracy: 0.6918\n",
            "Accuracy: 0.6918\n",
            "\n",
            "Model 8: for 30 batches and elu activation function and 150 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 9: for 30 batches and elu activation function and 200 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7482\n",
            "Accuracy: 0.7482\n",
            "\n",
            "Model 10: for 30 batches and elu activation function and 250 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.6878 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 11: for 30 batches and elu activation function and 300 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.6876 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 12: for 30 batches and elu activation function and 350 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.6889 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 13: for 30 batches and sigmoid activation function and 100 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 14: for 30 batches and sigmoid activation function and 150 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 15: for 30 batches and sigmoid activation function and 200 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 16: for 30 batches and sigmoid activation function and 250 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6874 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 17: for 30 batches and sigmoid activation function and 300 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6875 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 18: for 30 batches and sigmoid activation function and 350 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6874 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 19: for 50 batches and relu activation function and 100 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 20: for 50 batches and relu activation function and 150 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 21: for 50 batches and relu activation function and 200 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 22: for 50 batches and relu activation function and 250 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 23: for 50 batches and relu activation function and 300 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 24: for 50 batches and relu activation function and 350 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 25: for 50 batches and elu activation function and 100 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.2706 - accuracy: 0.6607\n",
            "Accuracy: 0.6607\n",
            "\n",
            "Model 26: for 50 batches and elu activation function and 150 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8661 - accuracy: 0.7264\n",
            "Accuracy: 0.7264\n",
            "\n",
            "Model 27: for 50 batches and elu activation function and 200 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.8990 - accuracy: 0.7150\n",
            "Accuracy: 0.7150\n",
            "\n",
            "Model 28: for 50 batches and elu activation function and 250 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 29: for 50 batches and elu activation function and 300 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6887 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 30: for 50 batches and elu activation function and 350 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 1s 6ms/step - loss: 0.6893 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 31: for 50 batches and sigmoid activation function and 100 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 32: for 50 batches and sigmoid activation function and 150 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 1s 6ms/step - loss: 0.6881 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 33: for 50 batches and sigmoid activation function and 200 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 1s 6ms/step - loss: 0.6882 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 34: for 50 batches and sigmoid activation function and 250 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6881 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 35: for 50 batches and sigmoid activation function and 300 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6882 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 36: for 50 batches and sigmoid activation function and 350 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6881 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 37: for 100 batches and relu activation function and 100 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 38: for 100 batches and relu activation function and 150 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 39: for 100 batches and relu activation function and 200 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 40: for 100 batches and relu activation function and 250 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6879 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 41: for 100 batches and relu activation function and 300 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6879 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 42: for 100 batches and relu activation function and 350 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6879 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 43: for 100 batches and elu activation function and 100 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.3834 - accuracy: 0.7071\n",
            "Accuracy: 0.7071\n",
            "\n",
            "Model 44: for 100 batches and elu activation function and 150 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7089 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 45: for 100 batches and elu activation function and 200 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 46: for 100 batches and elu activation function and 250 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.7425 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 47: for 100 batches and elu activation function and 300 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6903 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 48: for 100 batches and elu activation function and 350 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6903 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 49: for 100 batches and sigmoid activation function and 100 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 50: for 100 batches and sigmoid activation function and 150 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 51: for 100 batches and sigmoid activation function and 200 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 52: for 100 batches and sigmoid activation function and 250 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.6895 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 53: for 100 batches and sigmoid activation function and 300 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.6895 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n",
            "Model 54: for 100 batches and sigmoid activation function and 350 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.6896 - accuracy: 0.5582\n",
            "Accuracy: 0.5582\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Picking out the best model with the highest accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "k7scW-80lWBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_models = sorted(models, key=lambda x: x[0].evaluate(val_input, val_output)[1], reverse=True)[:1]\n",
        "\n",
        "for i, (model, batch, function, dimension) in enumerate(top_models):\n",
        "  print(f\"Model {i+1}: for {batch} batches and {function} activation function and {dimension} dimensions we had this accuracy:\")\n",
        "  accuracy = model.evaluate(val_input, val_output)[1]\n",
        "  print(f\"Accuracy: {accuracy:.4f}\\n\")\n",
        "  print(\"This is the highest accuracy obtained and hence we conclude this is the best predictive model.\")\n",
        "\n",
        "best_model = top_models[0]"
      ],
      "metadata": {
        "id": "tu0XO16olvA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede28e10-6654-4c9c-b4de-312da7e5ce80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6871 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6871 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6871 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9485 - accuracy: 0.6918\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7482\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6878 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6876 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6889 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6874 - accuracy: 0.5582\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.5582\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.6874 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.2706 - accuracy: 0.6607\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8661 - accuracy: 0.7264\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8990 - accuracy: 0.7150\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6887 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6893 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6881 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6882 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6881 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6879 - accuracy: 0.5582\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.6879 - accuracy: 0.5582\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.6879 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.3834 - accuracy: 0.7071\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7089 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.7425 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6903 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6895 - accuracy: 0.5582\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6896 - accuracy: 0.5582\n",
            "Model 1: for 30 batches and elu activation function and 200 dimensions we had this accuracy:\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7482\n",
            "Accuracy: 0.7482\n",
            "\n",
            "This is the highest accuracy obtained and hence we conclude this is the best predictive model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the best_model \n",
        "history = best_model[0].fit(train_input, train_output, epochs=EPOCHS, batch_size=best_model[1], validation_data=(val_input, val_output), callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlFA0pEMC9g_",
        "outputId": "dc392034-293f-47c3-91eb-71b992e8fe22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "178/178 [==============================] - 5s 26ms/step - loss: 0.3470 - accuracy: 0.8771 - val_loss: 0.5657 - val_accuracy: 0.7316\n",
            "Epoch 2/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.2583 - accuracy: 0.9142 - val_loss: 0.6164 - val_accuracy: 0.7351\n",
            "Epoch 3/15\n",
            "178/178 [==============================] - 5s 27ms/step - loss: 0.2062 - accuracy: 0.9356 - val_loss: 0.6893 - val_accuracy: 0.7277\n",
            "Epoch 4/15\n",
            "178/178 [==============================] - 5s 26ms/step - loss: 0.1680 - accuracy: 0.9473 - val_loss: 0.7136 - val_accuracy: 0.7412\n",
            "Epoch 5/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.1689 - accuracy: 0.9484 - val_loss: 0.7379 - val_accuracy: 0.7351\n",
            "Epoch 6/15\n",
            "178/178 [==============================] - 5s 29ms/step - loss: 0.1622 - accuracy: 0.9488 - val_loss: 0.7612 - val_accuracy: 0.7325\n",
            "Epoch 7/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.1545 - accuracy: 0.9486 - val_loss: 0.8409 - val_accuracy: 0.6996\n",
            "Epoch 8/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.1404 - accuracy: 0.9525 - val_loss: 0.9749 - val_accuracy: 0.6896\n",
            "Epoch 9/15\n",
            "178/178 [==============================] - 5s 28ms/step - loss: 0.1307 - accuracy: 0.9567 - val_loss: 0.8765 - val_accuracy: 0.7163\n",
            "Epoch 10/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.1320 - accuracy: 0.9557 - val_loss: 0.8596 - val_accuracy: 0.7198\n",
            "Epoch 11/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.1237 - accuracy: 0.9565 - val_loss: 0.9436 - val_accuracy: 0.7123\n",
            "Epoch 12/15\n",
            "178/178 [==============================] - 5s 29ms/step - loss: 0.1263 - accuracy: 0.9550 - val_loss: 0.9894 - val_accuracy: 0.7010\n",
            "Epoch 13/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.1176 - accuracy: 0.9567 - val_loss: 0.9928 - val_accuracy: 0.7058\n",
            "Epoch 14/15\n",
            "178/178 [==============================] - 4s 23ms/step - loss: 0.1183 - accuracy: 0.9565 - val_loss: 0.9558 - val_accuracy: 0.7123\n",
            "Epoch 15/15\n",
            "178/178 [==============================] - 5s 28ms/step - loss: 0.1151 - accuracy: 0.9572 - val_loss: 1.0345 - val_accuracy: 0.6996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspecting the results of the best model using line graph for accuracy and loss, confusion matrix and ROC curve\n"
      ],
      "metadata": {
        "id": "32O4BxIpUpZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating an animated visualisation to see the progression of accuracy and loss over the 15 epochs \n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def plot_graphs(train_loss, val_loss, train_accuracy, val_accuracy):\n",
        "    epochs = list(range(1, len(train_loss) + 1))\n",
        "\n",
        "    fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Loss\", \"Accuracy\"))\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=epochs, y=train_loss, mode='lines', name='Training Loss'), row=1, col=1)\n",
        "    fig.add_trace(go.Scatter(x=epochs, y=val_loss, mode='lines', name='Validation Loss'), row=1, col=1)\n",
        "    fig.add_trace(go.Scatter(x=epochs, y=train_accuracy, mode='lines', name='Training Accuracy'), row=1, col=2)\n",
        "    fig.add_trace(go.Scatter(x=epochs, y=val_accuracy, mode='lines', name='Validation Accuracy'), row=1, col=2)\n",
        "\n",
        "    fig.update_layout(height=400, width=800, title_text=\"Training and Validation Metrics\")\n",
        "\n",
        "    fig.update_xaxes(title_text=\"Epochs\", range=[max(1, len(train_loss) - 14), len(train_loss)], row=1, col=1)\n",
        "    fig.update_xaxes(title_text=\"Epochs\", range=[max(1, len(train_loss) - 14), len(train_loss)], row=1, col=2)\n",
        "\n",
        "    fig.update_yaxes(title_text=\"Loss\", range=[0, 1], row=1, col=1)\n",
        "    fig.update_yaxes(title_text=\"Accuracy\", range=[0, 1], row=1, col=2)\n",
        "\n",
        "    fig.update_layout(showlegend=True)\n",
        "\n",
        "    fig.update_layout(updatemenus=[dict(type=\"buttons\", buttons=[dict(label=\"Play\", method=\"animate\", args=[None, {}])])])\n",
        "\n",
        "    frames = []\n",
        "    frame_duration = 50  # Duration in milliseconds\n",
        "\n",
        "    for i in range(len(epochs)):\n",
        "        frame = go.Frame(\n",
        "            data=[\n",
        "                go.Scatter(x=epochs[:i + 1], y=train_loss[:i + 1], mode='lines', name='Training Loss'),\n",
        "                go.Scatter(x=epochs[:i + 1], y=val_loss[:i + 1], mode='lines', name='Validation Loss'),\n",
        "                go.Scatter(x=epochs[:i + 1], y=train_accuracy[:i + 1], mode='lines', name='Training Accuracy'),\n",
        "                go.Scatter(x=epochs[:i + 1], y=val_accuracy[:i + 1], mode='lines', name='Validation Accuracy'),\n",
        "            ],\n",
        "            name=f\"frame{i + 1}\",\n",
        "            layout=dict(annotations=[dict(text=f\"Epoch {i+1}\", showarrow=False, x=0.5, y=-0.15)]),\n",
        "            traces=[0, 1, 2, 3]\n",
        "        )\n",
        "\n",
        "        frames.append(frame)\n",
        "\n",
        "        # Add additional frames to create a delay between each epoch\n",
        "        for _ in range(frame_duration // 100):\n",
        "            frames.append(go.Frame(data=frame.data))\n",
        "\n",
        "    fig.frames = frames\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "train_loss = [0.3470, 0.2583, 0.2062, 0.1680, 0.1689, 0.1622, 0.1545, 0.1404, 0.1307, 0.1320, 0.1237, 0.1263, 0.1176, 0.1183, 0.1151]\n",
        "val_loss = [0.5657, 0.6164, 0.6893, 0.7136, 0.7379, 0.7612, 0.8409, 0.9749, 0.8765, 0.8596, 0.9436, 0.9894, 0.9928, 0.9558, 1.0345]\n",
        "train_accuracy = [0.8771, 0.9142, 0.9356, 0.9473, 0.9484, 0.9488, 0.9486, 0.9525, 0.9567, 0.9557, 0.9565, 0.9550, 0.9567, 0.9565, 0.9572]\n",
        "val_accuracy = [0.7316, 0.7351, 0.7277, 0.7412, 0.7351, 0.7325, 0.6996, 0.6896, 0.7163, 0.7198, 0.7123, 0.7010, 0.7058, 0.7123, 0.6996]\n",
        "\n",
        "plot_graphs(train_loss, val_loss, train_accuracy, val_accuracy)\n",
        "#Reference: https://plotly.com/python/animations/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "tonH23X8MOO5",
        "outputId": "84024973-3dad-4008-bada-fc4b8fd09c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"3982232a-b84a-4bf8-bca1-a20e274c1575\" class=\"plotly-graph-div\" style=\"height:400px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3982232a-b84a-4bf8-bca1-a20e274c1575\")) {                    Plotly.newPlot(                        \"3982232a-b84a-4bf8-bca1-a20e274c1575\",                        [{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.347,0.2583,0.2062,0.168,0.1689,0.1622,0.1545,0.1404,0.1307,0.132,0.1237,0.1263,0.1176,0.1183,0.1151],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.5657,0.6164,0.6893,0.7136,0.7379,0.7612,0.8409,0.9749,0.8765,0.8596,0.9436,0.9894,0.9928,0.9558,1.0345],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.8771,0.9142,0.9356,0.9473,0.9484,0.9488,0.9486,0.9525,0.9567,0.9557,0.9565,0.955,0.9567,0.9565,0.9572],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.7316,0.7351,0.7277,0.7412,0.7351,0.7325,0.6996,0.6896,0.7163,0.7198,0.7123,0.701,0.7058,0.7123,0.6996],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Epochs\"},\"range\":[1,15]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"},\"range\":[0,1]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Epochs\"},\"range\":[1,15]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Accuracy\"},\"range\":[0,1]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Loss\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Accuracy\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Training and Validation Metrics\"},\"height\":400,\"width\":800,\"showlegend\":true,\"updatemenus\":[{\"buttons\":[{\"args\":[null,{}],\"label\":\"Play\",\"method\":\"animate\"}],\"type\":\"buttons\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            Plotly.addFrames('3982232a-b84a-4bf8-bca1-a20e274c1575', [{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1],\"y\":[0.347],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1],\"y\":[0.5657],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1],\"y\":[0.8771],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1],\"y\":[0.7316],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 1\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame1\",\"traces\":[0,1,2,3]},{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2],\"y\":[0.347,0.2583],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2],\"y\":[0.5657,0.6164],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2],\"y\":[0.8771,0.9142],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2],\"y\":[0.7316,0.7351],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 2\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame2\",\"traces\":[0,1,2,3]},{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2,3],\"y\":[0.347,0.2583,0.2062],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2,3],\"y\":[0.5657,0.6164,0.6893],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2,3],\"y\":[0.8771,0.9142,0.9356],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3],\"y\":[0.7316,0.7351,0.7277],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 3\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame3\",\"traces\":[0,1,2,3]},{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2,3,4],\"y\":[0.347,0.2583,0.2062,0.168],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4],\"y\":[0.5657,0.6164,0.6893,0.7136],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4],\"y\":[0.8771,0.9142,0.9356,0.9473],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4],\"y\":[0.7316,0.7351,0.7277,0.7412],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 4\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame4\",\"traces\":[0,1,2,3]},{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2,3,4,5],\"y\":[0.347,0.2583,0.2062,0.168,0.1689],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4,5],\"y\":[0.5657,0.6164,0.6893,0.7136,0.7379],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4,5],\"y\":[0.8771,0.9142,0.9356,0.9473,0.9484],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4,5],\"y\":[0.7316,0.7351,0.7277,0.7412,0.7351],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 5\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame5\",\"traces\":[0,1,2,3]},{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2,3,4,5,6],\"y\":[0.347,0.2583,0.2062,0.168,0.1689,0.1622],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4,5,6],\"y\":[0.5657,0.6164,0.6893,0.7136,0.7379,0.7612],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4,5,6],\"y\":[0.8771,0.9142,0.9356,0.9473,0.9484,0.9488],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4,5,6],\"y\":[0.7316,0.7351,0.7277,0.7412,0.7351,0.7325],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 6\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame6\",\"traces\":[0,1,2,3]},{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2,3,4,5,6,7],\"y\":[0.347,0.2583,0.2062,0.168,0.1689,0.1622,0.1545],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4,5,6,7],\"y\":[0.5657,0.6164,0.6893,0.7136,0.7379,0.7612,0.8409],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4,5,6,7],\"y\":[0.8771,0.9142,0.9356,0.9473,0.9484,0.9488,0.9486],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4,5,6,7],\"y\":[0.7316,0.7351,0.7277,0.7412,0.7351,0.7325,0.6996],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 7\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame7\",\"traces\":[0,1,2,3]},{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2,3,4,5,6,7,8],\"y\":[0.347,0.2583,0.2062,0.168,0.1689,0.1622,0.1545,0.1404],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4,5,6,7,8],\"y\":[0.5657,0.6164,0.6893,0.7136,0.7379,0.7612,0.8409,0.9749],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4,5,6,7,8],\"y\":[0.8771,0.9142,0.9356,0.9473,0.9484,0.9488,0.9486,0.9525],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4,5,6,7,8],\"y\":[0.7316,0.7351,0.7277,0.7412,0.7351,0.7325,0.6996,0.6896],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 8\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame8\",\"traces\":[0,1,2,3]},{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2,3,4,5,6,7,8,9],\"y\":[0.347,0.2583,0.2062,0.168,0.1689,0.1622,0.1545,0.1404,0.1307],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4,5,6,7,8,9],\"y\":[0.5657,0.6164,0.6893,0.7136,0.7379,0.7612,0.8409,0.9749,0.8765],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9],\"y\":[0.8771,0.9142,0.9356,0.9473,0.9484,0.9488,0.9486,0.9525,0.9567],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9],\"y\":[0.7316,0.7351,0.7277,0.7412,0.7351,0.7325,0.6996,0.6896,0.7163],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 9\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame9\",\"traces\":[0,1,2,3]},{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.347,0.2583,0.2062,0.168,0.1689,0.1622,0.1545,0.1404,0.1307,0.132],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.5657,0.6164,0.6893,0.7136,0.7379,0.7612,0.8409,0.9749,0.8765,0.8596],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.8771,0.9142,0.9356,0.9473,0.9484,0.9488,0.9486,0.9525,0.9567,0.9557],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.7316,0.7351,0.7277,0.7412,0.7351,0.7325,0.6996,0.6896,0.7163,0.7198],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 10\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame10\",\"traces\":[0,1,2,3]},{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11],\"y\":[0.347,0.2583,0.2062,0.168,0.1689,0.1622,0.1545,0.1404,0.1307,0.132,0.1237],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11],\"y\":[0.5657,0.6164,0.6893,0.7136,0.7379,0.7612,0.8409,0.9749,0.8765,0.8596,0.9436],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11],\"y\":[0.8771,0.9142,0.9356,0.9473,0.9484,0.9488,0.9486,0.9525,0.9567,0.9557,0.9565],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11],\"y\":[0.7316,0.7351,0.7277,0.7412,0.7351,0.7325,0.6996,0.6896,0.7163,0.7198,0.7123],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 11\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame11\",\"traces\":[0,1,2,3]},{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12],\"y\":[0.347,0.2583,0.2062,0.168,0.1689,0.1622,0.1545,0.1404,0.1307,0.132,0.1237,0.1263],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12],\"y\":[0.5657,0.6164,0.6893,0.7136,0.7379,0.7612,0.8409,0.9749,0.8765,0.8596,0.9436,0.9894],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12],\"y\":[0.8771,0.9142,0.9356,0.9473,0.9484,0.9488,0.9486,0.9525,0.9567,0.9557,0.9565,0.955],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12],\"y\":[0.7316,0.7351,0.7277,0.7412,0.7351,0.7325,0.6996,0.6896,0.7163,0.7198,0.7123,0.701],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 12\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame12\",\"traces\":[0,1,2,3]},{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13],\"y\":[0.347,0.2583,0.2062,0.168,0.1689,0.1622,0.1545,0.1404,0.1307,0.132,0.1237,0.1263,0.1176],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13],\"y\":[0.5657,0.6164,0.6893,0.7136,0.7379,0.7612,0.8409,0.9749,0.8765,0.8596,0.9436,0.9894,0.9928],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13],\"y\":[0.8771,0.9142,0.9356,0.9473,0.9484,0.9488,0.9486,0.9525,0.9567,0.9557,0.9565,0.955,0.9567],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13],\"y\":[0.7316,0.7351,0.7277,0.7412,0.7351,0.7325,0.6996,0.6896,0.7163,0.7198,0.7123,0.701,0.7058],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 13\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame13\",\"traces\":[0,1,2,3]},{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.347,0.2583,0.2062,0.168,0.1689,0.1622,0.1545,0.1404,0.1307,0.132,0.1237,0.1263,0.1176,0.1183],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.5657,0.6164,0.6893,0.7136,0.7379,0.7612,0.8409,0.9749,0.8765,0.8596,0.9436,0.9894,0.9928,0.9558],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.8771,0.9142,0.9356,0.9473,0.9484,0.9488,0.9486,0.9525,0.9567,0.9557,0.9565,0.955,0.9567,0.9565],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.7316,0.7351,0.7277,0.7412,0.7351,0.7325,0.6996,0.6896,0.7163,0.7198,0.7123,0.701,0.7058,0.7123],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 14\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame14\",\"traces\":[0,1,2,3]},{\"data\":[{\"mode\":\"lines\",\"name\":\"Training Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.347,0.2583,0.2062,0.168,0.1689,0.1622,0.1545,0.1404,0.1307,0.132,0.1237,0.1263,0.1176,0.1183,0.1151],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.5657,0.6164,0.6893,0.7136,0.7379,0.7612,0.8409,0.9749,0.8765,0.8596,0.9436,0.9894,0.9928,0.9558,1.0345],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.8771,0.9142,0.9356,0.9473,0.9484,0.9488,0.9486,0.9525,0.9567,0.9557,0.9565,0.955,0.9567,0.9565,0.9572],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.7316,0.7351,0.7277,0.7412,0.7351,0.7325,0.6996,0.6896,0.7163,0.7198,0.7123,0.701,0.7058,0.7123,0.6996],\"type\":\"scatter\"}],\"layout\":{\"annotations\":[{\"showarrow\":false,\"text\":\"Epoch 15\",\"x\":0.5,\"y\":-0.15}]},\"name\":\"frame15\",\"traces\":[0,1,2,3]}]);\n",
              "                        }).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3982232a-b84a-4bf8-bca1-a20e274c1575');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion matrix for the best model"
      ],
      "metadata": {
        "id": "1RWxrCoAIsi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Generating a confusion matrix\n",
        "def get_confusion_matrix(y_true, y_pred, labels):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "    return cm_df\n",
        "\n",
        "y_val_pred = best_model[0].predict(val_input)\n",
        "y_val_pred = np.round(y_val_pred).flatten()\n",
        "\n",
        "labels = ['Not Disaster', 'Disaster']\n",
        "cm_df = get_confusion_matrix(val_output, y_val_pred, labels)\n",
        "\n",
        "#Plotting the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_df, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "sf9h59PV2Bvp",
        "outputId": "1a5fcacf-f849-44fe-f7e9-d172ebed2d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72/72 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROC Curve for the best model\n"
      ],
      "metadata": {
        "id": "cnKeZGpmJIfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "#Plotting the ROC curve\n",
        "def plot_roc_curve(y_true, y_pred_prob):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "plot_roc_curve(val_output, y_val_pred)"
      ],
      "metadata": {
        "id": "PcnSd3P4JORN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "fc4495d7-bb62-4eef-f3ad-955d3c4a0feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYaaeMQhoL-h"
      },
      "source": [
        "##Prepare for submission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vhY_-6xoOQL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce4ca00a-2352-4358-9925-19ed439a5836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102/102 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9692d8e7-94ad-4bda-8dd7-afcfb845b54f\", \"submission.csv\", 22746)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "df_test_pred = preprocess_text(df_test_text)\n",
        "test_padded_seq = seq_and_pad(df_test_pred, tokenizer, PADDING, MAXLEN)\n",
        "df_test_pred = best_model[0].predict(test_padded_seq)\n",
        "submission['target'] = df_test_pred.round().astype(int)\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "files.download('submission.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}